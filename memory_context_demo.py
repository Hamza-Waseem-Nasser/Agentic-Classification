"""
ğŸ§  PRACTICAL MEMORY AND CONTEXT DEMONSTRATION
Educational Code Examples for Multi-Agent ITSM System

This file shows exactly how memory and context flow through your agents
with real code examples and detailed explanations.
"""

from typing import Dict, Any, List
from datetime import datetime
import json

# ==============================================================================
# 1. SHARED STATE MEMORY EXAMPLE
# ==============================================================================

class TicketStateDemo:
    """
    Demonstrates how shared state flows through agents.
    This is the PRIMARY memory sharing mechanism in your system.
    """
    
    def __init__(self):
        # Initial state when ticket enters pipeline
        self.initial_state = {
            "ticket_id": "demo_ticket_001",
            "original_text": "Ø¨Ø¹Ø¯ ØªØ³Ø¬ÙŠÙ„ Ø¯Ø®ÙˆÙ„ ÙˆØ§Ø³ØªÙƒÙ…Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¸Ù‡Ø± Ù„ÙŠ Ø§Ù† Ø§Ù„Ø´Ø±ÙƒÙ‡ Ù…Ø³Ø¬Ù„Ù‡",
            "created_at": datetime.now().isoformat(),
            
            # Empty fields to be filled by agents
            "processed_text": None,
            "classification": {},
            "metadata": {},
            "processing_metadata": {},
            "arabic_processing": {},
            "classification_metadata": {}
        }
    
    def demonstrate_state_evolution(self):
        """Shows how state evolves through each agent"""
        
        print("ğŸ¯ INITIAL STATE:")
        print(json.dumps(self.initial_state, indent=2, ensure_ascii=False))
        
        # AGENT 1: Orchestrator adds routing and business logic
        after_orchestrator = self.initial_state.copy()
        after_orchestrator.update({
            "priority": "normal",
            "routing_decisions": {
                "complexity_score": 0.35,
                "processing_path": "standard",
                "priority_detected": False,
                "complexity_factors": {
                    "text_length": 59,
                    "has_technical_terms": True,
                    "has_arabic_mixed_languages": False
                }
            },
            "processing_metadata": {
                "orchestrator_start": datetime.now().isoformat(),
                "hierarchy_loaded": True,
                "total_categories": 19,
                "timeouts": {"arabic_processing": 30, "category_classification": 45}
            }
        })
        
        print("\nğŸ­ AFTER ORCHESTRATOR:")
        print(json.dumps(after_orchestrator, indent=2, ensure_ascii=False))
        
        # AGENT 2: Arabic Processor adds linguistic analysis
        after_arabic = after_orchestrator.copy()
        after_arabic.update({
            "processed_text": "ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙˆØ§Ø³ØªÙƒÙ…Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ ÙˆØªØ¨ÙŠÙ† Ø£Ù† Ø§Ù„Ø´Ø±ÙƒØ© Ù…Ø³Ø¬Ù„Ø©.",
            "technical_terms": ["ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„", "Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"],
            "language_confidence": 0.59,
            "entities": [],
            "arabic_processing": {
                "dialect_detected": "msa",
                "normalization_applied": True,
                "technical_terms_found": 2,
                "processing_confidence": 0.59,
                "quality_metrics": {
                    "arabic_ratio": 0.95,
                    "length_score": 0.7
                }
            }
        })
        
        print("\nğŸ”¤ AFTER ARABIC PROCESSOR:")
        print(json.dumps(after_arabic, indent=2, ensure_ascii=False))
        
        # AGENT 3: Category Classifier adds main classification
        after_category = after_arabic.copy()
        after_category.update({
            "classification": {
                "main_category": "Ø§Ù„ØªØ³Ø¬ÙŠÙ„",
                "main_category_description": "Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…",
                "confidence_score": 0.85
            },
            "category_confidence": 0.85,  # Backward compatibility
            "classification_metadata": {
                "category_agent": {
                    "processing_timestamp": datetime.now().isoformat(),
                    "similar_categories_found": 3,
                    "classification_method": "llm_with_vector_context",
                    "reasoning": "Ø§Ù„Ù†Øµ ÙŠØªØ­Ø¯Ø« Ø¹Ù† Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ³Ø¬ÙŠÙ„"
                }
            }
        })
        
        print("\nğŸ·ï¸ AFTER CATEGORY CLASSIFIER:")
        print(json.dumps(after_category, indent=2, ensure_ascii=False))
        
        # AGENT 4: Subcategory Classifier completes classification
        final_state = after_category.copy()
        final_state.update({
            "classification": {
                **after_category["classification"],
                "subcategory": "Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ",
                "subcategory_description": "Ù…Ø´Ø§ÙƒÙ„ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ",
                "confidence_score": 0.8  # Final overall confidence
            },
            "subcategory_confidence": 0.8,
            "processing_completed": datetime.now().isoformat(),
            "classification_metadata": {
                **after_category["classification_metadata"],
                "subcategory_agent": {
                    "parent_category": "Ø§Ù„ØªØ³Ø¬ÙŠÙ„",
                    "subcategories_considered": 3,
                    "reasoning": "Ø§Ù„Ù†Øµ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ"
                }
            }
        })
        
        print("\nğŸ” FINAL STATE (After Subcategory Classifier):")
        print(json.dumps(final_state, indent=2, ensure_ascii=False))


# ==============================================================================
# 2. INDIVIDUAL AGENT MEMORY EXAMPLES
# ==============================================================================

class AgentMemoryDemo:
    """
    Demonstrates individual agent memory - private to each agent.
    """
    
    def __init__(self):
        # Each agent has its own private memory
        self.orchestrator_memory = {
            "business_rules": {
                "priority_keywords": ["Ø¹Ø§Ø¬Ù„", "Ø·Ø§Ø±Ø¦", "Ù…Ù‡Ù…", "Ø³Ø±ÙŠØ¹"],
                "confidence_thresholds": {
                    "high_confidence": 0.85,
                    "medium_confidence": 0.65,
                    "low_confidence": 0.45
                }
            },
            "category_loader": "Reference to CategoryLoader instance",
            "state_manager": "Reference to StateManager instance"
        }
        
        self.arabic_processor_memory = {
            "technical_glossary": {
                "ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„": "login", 
                "Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª": "data",
                "Ø§Ù„Ù†Ø¸Ø§Ù…": "system",
                "Ø§Ù„ØªØ·Ø¨ÙŠÙ‚": "application",
                "ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±": "password",
                "Ø­Ø³Ø§Ø¨": "account"
            },
            "dialect_markers": {
                "gulf": ["Ø´Ù„ÙˆÙ†", "ÙˆØ´", "Ù‡Ø°Ø§", "Ø°Ø§Ùƒ"],
                "levantine": ["ÙƒÙŠÙ", "ÙˆÙŠÙ†", "Ù‡Ø§Ø¯", "Ù‡Ø§ÙŠ"],
                "egyptian": ["Ø§Ø²Ø§ÙŠ", "ÙÙŠÙ†", "Ø¯Ù‡", "Ø¯ÙŠ"]
            },
            "normalization_rules": [
                ("Ø£", "Ø§"), ("Ø¥", "Ø§"), ("Ø¢", "Ø§"),  # Alef variants
                ("Ù‰", "ÙŠ"),  # Yaa variants
                ("Ø©", "Ù‡")   # Taa marbouta
            ]
        }
        
        self.category_classifier_memory = {
            "qdrant_client": "QdrantClient instance",
            "collection_name": "itsm_categories",
            "embedding_model": "text-embedding-3-small",
            "top_k_candidates": 5,
            "similarity_threshold": 0.5,
            "few_shot_cache": {
                "Ø§Ù„ØªØ³Ø¬ÙŠÙ„": {
                    "positive_examples": [
                        "Ø¨Ø¹Ø¯ ØªØ³Ø¬ÙŠÙ„ Ø¯Ø®ÙˆÙ„ ÙˆØ§Ø³ØªÙƒÙ…Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¸Ù‡Ø± Ù„ÙŠ Ø§Ù† Ø§Ù„Ø´Ø±ÙƒÙ‡ Ù…Ø³Ø¬Ù„Ù‡",
                        "Ù„Ø§ Ø£Ø³ØªØ·ÙŠØ¹ Ø¥ÙƒÙ…Ø§Ù„ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ³Ø¬ÙŠÙ„"
                    ]
                }
            }
        }
        
        self.subcategory_classifier_memory = {
            "hierarchy": "Reference to ClassificationHierarchy",
            "top_k_subcategories": 3,
            "minimum_confidence": 0.6,
            "category_configs": {
                "Ø§Ù„ØªØ³Ø¬ÙŠÙ„": {
                    "subcategories": ["Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ", "Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"],
                    "default_confidence": 0.7
                }
            }
        }
    
    def demonstrate_memory_isolation(self):
        """Shows how each agent has private memory"""
        
        print("ğŸ­ ORCHESTRATOR PRIVATE MEMORY:")
        print(json.dumps(self.orchestrator_memory, indent=2, ensure_ascii=False))
        
        print("\nğŸ”¤ ARABIC PROCESSOR PRIVATE MEMORY:")
        print(json.dumps(self.arabic_processor_memory, indent=2, ensure_ascii=False))
        
        print("\nğŸ·ï¸ CATEGORY CLASSIFIER PRIVATE MEMORY:")
        print(json.dumps(self.category_classifier_memory, indent=2, ensure_ascii=False))
        
        print("\nğŸ” SUBCATEGORY CLASSIFIER PRIVATE MEMORY:")
        print(json.dumps(self.subcategory_classifier_memory, indent=2, ensure_ascii=False))


# ==============================================================================
# 3. VECTOR SEMANTIC MEMORY EXAMPLE
# ==============================================================================

class VectorMemoryDemo:
    """
    Demonstrates vector embeddings stored in Qdrant database.
    This is the SEMANTIC MEMORY that enables intelligent similarity search.
    """
    
    def __init__(self):
        # What gets embedded and stored in Qdrant
        self.embedded_content = {
            "categories": [
                {
                    "id": 1,
                    "category_name": "Ø§Ù„ØªØ³Ø¬ÙŠÙ„",
                    "text_to_embed": "Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… ÙˆØ¥Ù†Ø´Ø§Ø¡ Ø­Ø³Ø§Ø¨Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©",
                    "embedding": "[1536 float values]",  # Actual embedding from OpenAI
                    "metadata": {
                        "type": "main_category",
                        "subcategory_count": 5,
                        "keywords": ["ØªØ³Ø¬ÙŠÙ„", "Ø­Ø³Ø§Ø¨", "Ø¥Ù†Ø´Ø§Ø¡"]
                    }
                },
                {
                    "id": 2,
                    "category_name": "ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„", 
                    "text_to_embed": "ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ù„Ù„Ù…Ù†ØµØ© ÙˆÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±",
                    "embedding": "[1536 float values]",
                    "metadata": {
                        "type": "main_category",
                        "subcategory_count": 3,
                        "keywords": ["Ø¯Ø®ÙˆÙ„", "Ù„ÙˆØ¬ÙŠÙ†", "ÙƒÙ„Ù…Ø© Ù…Ø±ÙˆØ±"]
                    }
                }
            ],
            "subcategories": [
                {
                    "id": 101,
                    "category_name": "Ø§Ù„ØªØ³Ø¬ÙŠÙ„",
                    "subcategory_name": "Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ",
                    "text_to_embed": "Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ Ù…Ø´Ø§ÙƒÙ„ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ",
                    "embedding": "[1536 float values]",
                    "metadata": {
                        "type": "subcategory_context",
                        "parent_category": "Ø§Ù„ØªØ³Ø¬ÙŠÙ„"
                    }
                }
            ],
            "training_examples": [
                {
                    "id": 1001,
                    "category_name": "Ø§Ù„ØªØ³Ø¬ÙŠÙ„",
                    "example_text": "Ø¨Ø¹Ø¯ ØªØ³Ø¬ÙŠÙ„ Ø¯Ø®ÙˆÙ„ ÙˆØ§Ø³ØªÙƒÙ…Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¸Ù‡Ø± Ù„ÙŠ Ø§Ù† Ø§Ù„Ø´Ø±ÙƒÙ‡ Ù…Ø³Ø¬Ù„Ù‡",
                    "embedding": "[1536 float values]",
                    "metadata": {
                        "type": "training_example",
                        "category": "Ø§Ù„ØªØ³Ø¬ÙŠÙ„"
                    }
                }
            ]
        }
    
    def demonstrate_vector_search_process(self):
        """Shows how vector search works step by step"""
        
        print("ğŸ§  VECTOR SEARCH PROCESS:")
        print("=" * 50)
        
        # Step 1: Query comes in
        query_text = "ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙˆØ§Ø³ØªÙƒÙ…Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ ÙˆØªØ¨ÙŠÙ† Ø£Ù† Ø§Ù„Ø´Ø±ÙƒØ© Ù…Ø³Ø¬Ù„Ø©."
        print(f"1. Query Text: {query_text}")
        
        # Step 2: Generate embedding for query
        print("2. Generate Embedding:")
        print("   - API Call: POST https://api.openai.com/v1/embeddings")
        print("   - Model: text-embedding-3-small")
        print("   - Result: [1536 dimensional vector]")
        
        # Step 3: Search in Qdrant
        print("3. Vector Search in Qdrant:")
        print("   - Collection: itsm_categories")
        print("   - Query Vector: [1536 dimensions]")
        print("   - Search Method: Cosine Similarity")
        print("   - Limit: 10 results")
        print("   - Threshold: 0.5")
        
        # Step 4: Results
        search_results = [
            {"category": "Ø§Ù„ØªØ³Ø¬ÙŠÙ„", "similarity_score": 0.87, "metadata": {"type": "main_category"}},
            {"category": "Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ", "similarity_score": 0.82, "metadata": {"type": "subcategory"}},
            {"category": "ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„", "similarity_score": 0.65, "metadata": {"type": "main_category"}},
            {"category": "Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†Ø´Ø£Ø©", "similarity_score": 0.45, "metadata": {"type": "main_category"}}
        ]
        
        print("4. Search Results:")
        for i, result in enumerate(search_results, 1):
            print(f"   {i}. {result['category']} (score: {result['similarity_score']})")
        
        # Step 5: Context for LLM
        print("5. Context Provided to LLM:")
        top_categories = [r['category'] for r in search_results if r['metadata']['type'] == 'main_category'][:3]
        print(f"   - Top Similar Categories: {top_categories}")
        print("   - This context helps LLM make informed decision")


# ==============================================================================
# 4. LLM CONVERSATION MEMORY EXAMPLE  
# ==============================================================================

class LLMContextDemo:
    """
    Demonstrates how LLM conversation memory works within each agent.
    """
    
    def __init__(self):
        # Example conversation memory for Category Classifier
        self.category_classifier_conversation = [
            {
                "role": "system",
                "content": """
                Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªØµÙ†ÙŠÙ ØªØ°Ø§ÙƒØ± Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ØªÙ‚Ù†ÙŠ Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª.
                
                Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹: ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ø§Ø®ØªÙŠØ§Ø± ÙØ¦Ø© Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© ÙÙ‚Ø·.
                
                Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© ÙÙ‚Ø· Ù‡ÙŠ:
                Ø§Ù„ØªØ³Ø¬ÙŠÙ„, ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„, Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†Ø´Ø£Ø©, Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª
                
                Ø§Ø³ØªØ®Ø¯Ù… Chain-of-Thought reasoning:
                1. Ø£ÙˆÙ„Ø§Ù‹ØŒ Ø§Ù‚Ø±Ø£ Ø§Ù„Ù†Øµ ÙˆØ­Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
                2. Ø«Ø§Ù†ÙŠØ§Ù‹ØŒ Ù‚Ø§Ø±Ù† Ù…Ø¹ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©  
                3. Ø«Ø§Ù„Ø«Ø§Ù‹ØŒ Ø§Ø®ØªØ± Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø£Ù†Ø³Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„
                """
            },
            {
                "role": "user",
                "content": """
                Ø§Ù„Ù†Øµ: ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙˆØ§Ø³ØªÙƒÙ…Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ ÙˆØªØ¨ÙŠÙ† Ø£Ù† Ø§Ù„Ø´Ø±ÙƒØ© Ù…Ø³Ø¬Ù„Ø©.
                
                Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø© Ù…Ù† Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ:
                1. Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (similarity: 0.87)
                2. ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ (similarity: 0.65)
                3. Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†Ø´Ø£Ø© (similarity: 0.45)
                
                ØµÙ†Ù Ø§Ù„Ù†Øµ ÙˆØ§Ø®ØªØ± Ø§Ù„ÙØ¦Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©.
                """
            },
            {
                "role": "assistant", 
                "content": """
                {
                    "category": "Ø§Ù„ØªØ³Ø¬ÙŠÙ„",
                    "confidence": 0.85,
                    "reasoning": "Ø§Ù„Ù†Øµ ÙŠØªØ­Ø¯Ø« Ø¹Ù† Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø­ÙŠØ« ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø£Ù† Ø§Ù„Ø´Ø±ÙƒØ© Ù…Ø³Ø¬Ù„Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹",
                    "chain_of_thought": "Ø£ÙˆÙ„Ø§Ù‹: Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ù‡ÙŠ 'ØªØ³Ø¬ÙŠÙ„' Ùˆ'Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª' Ùˆ'Ø§Ù„Ø´Ø±ÙƒØ© Ù…Ø³Ø¬Ù„Ø©'. Ø«Ø§Ù†ÙŠØ§Ù‹: Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© ØªØ¸Ù‡Ø± Ø£Ù† 'Ø§Ù„ØªØ³Ø¬ÙŠÙ„' Ù‡Ùˆ Ø§Ù„Ø£Ù†Ø³Ø¨ Ù„Ø£Ù† Ø§Ù„Ù…Ø´ÙƒÙ„Ø© ØªØªØ¹Ù„Ù‚ Ø¨Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙˆÙ„ÙŠØ³ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„. Ø«Ø§Ù„Ø«Ø§Ù‹: Ø§Ù„Ø«Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© 0.85 Ù„Ø£Ù† Ø§Ù„Ø³ÙŠØ§Ù‚ ÙˆØ§Ø¶Ø­ ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© ØªØ¤ÙƒØ¯ Ù‡Ø°Ø§ Ø§Ù„ØªØµÙ†ÙŠÙ."
                }
                """
            }
        ]
    
    def demonstrate_llm_context_evolution(self):
        """Shows how LLM context builds up during conversation"""
        
        print("ğŸ¤– LLM CONVERSATION MEMORY EVOLUTION:")
        print("=" * 60)
        
        for i, message in enumerate(self.category_classifier_conversation, 1):
            print(f"\nMessage {i} ({message['role'].upper()}):")
            print("-" * 30)
            print(message['content'][:200] + "..." if len(message['content']) > 200 else message['content'])
        
        print("\nğŸ’¡ KEY INSIGHTS:")
        print("- System message sets the expert role and constraints")
        print("- User message provides text + vector search context")  
        print("- Assistant response includes reasoning and chain-of-thought")
        print("- Each API call is independent (no conversation persistence)")


# ==============================================================================
# 5. CONTEXT SHARING PATTERNS DEMONSTRATION
# ==============================================================================

class ContextSharingDemo:
    """
    Demonstrates the different patterns of context sharing between agents.
    """
    
    def demonstrate_hierarchical_context(self):
        """Shows how subcategory agent inherits context from category agent"""
        
        print("ğŸ—ï¸ HIERARCHICAL CONTEXT INHERITANCE:")
        print("=" * 50)
        
        # Context from previous agents available to subcategory classifier
        inherited_context = {
            "from_orchestrator": {
                "priority": "normal",
                "complexity_score": 0.35,
                "processing_path": "standard"
            },
            "from_arabic_processor": {
                "processed_text": "ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙˆØ§Ø³ØªÙƒÙ…Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ ÙˆØªØ¨ÙŠÙ† Ø£Ù† Ø§Ù„Ø´Ø±ÙƒØ© Ù…Ø³Ø¬Ù„Ø©.",
                "technical_terms": ["ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„", "Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"],
                "language_confidence": 0.59,
                "dialect_detected": "msa"
            },
            "from_category_classifier": {
                "main_category": "Ø§Ù„ØªØ³Ø¬ÙŠÙ„",
                "category_confidence": 0.85,
                "similar_categories": ["ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„", "Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†Ø´Ø£Ø©"],
                "classification_reasoning": "Ø§Ù„Ù†Øµ ÙŠØªØ­Ø¯Ø« Ø¹Ù† Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ³Ø¬ÙŠÙ„"
            }
        }
        
        print("Context Available to Subcategory Classifier:")
        print(json.dumps(inherited_context, indent=2, ensure_ascii=False))
        
        # How subcategory agent uses this context
        subcategory_decision_process = {
            "step_1_filter_subcategories": {
                "parent_category": "Ø§Ù„ØªØ³Ø¬ÙŠÙ„",
                "available_subcategories": [
                    "Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ",
                    "Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", 
                    "Ø¥Ù†Ø´Ø§Ø¡ Ø­Ø³Ø§Ø¨ Ø¬Ø¯ÙŠØ¯"
                ]
            },
            "step_2_analyze_context": {
                "key_phrases": ["Ø§Ù„Ø´Ø±ÙƒØ© Ù…Ø³Ø¬Ù„Ø©", "Ø§Ø³ØªÙƒÙ…Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"],
                "technical_terms": ["ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„", "Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"],
                "category_confidence": 0.85  # High confidence from previous agent
            },
            "step_3_make_decision": {
                "chosen_subcategory": "Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ",
                "reasoning": "Ø§Ù„Ø¹Ø¨Ø§Ø±Ø© 'Ø§Ù„Ø´Ø±ÙƒØ© Ù…Ø³Ø¬Ù„Ø©' ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ"
            }
        }
        
        print("\nSubcategory Decision Process:")
        print(json.dumps(subcategory_decision_process, indent=2, ensure_ascii=False))


# ==============================================================================
# 6. COMPREHENSIVE DEMO RUNNER
# ==============================================================================

def run_memory_and_context_demo():
    """
    Runs all demonstrations to show complete memory and context flow.
    """
    
    print("ğŸ§  MULTI-AGENT MEMORY AND CONTEXT DEMONSTRATION")
    print("=" * 80)
    print("This demo shows exactly how memory and context flow through your agents.")
    print("=" * 80)
    
    # Demo 1: Shared State Evolution
    print("\n\n1ï¸âƒ£ SHARED STATE MEMORY EVOLUTION")
    print("-" * 40)
    state_demo = TicketStateDemo()
    state_demo.demonstrate_state_evolution()
    
    # Demo 2: Individual Agent Memory
    print("\n\n2ï¸âƒ£ INDIVIDUAL AGENT MEMORY")
    print("-" * 40)
    agent_demo = AgentMemoryDemo()
    agent_demo.demonstrate_memory_isolation()
    
    # Demo 3: Vector Semantic Memory
    print("\n\n3ï¸âƒ£ VECTOR SEMANTIC MEMORY")
    print("-" * 40)
    vector_demo = VectorMemoryDemo()
    vector_demo.demonstrate_vector_search_process()
    
    # Demo 4: LLM Conversation Memory
    print("\n\n4ï¸âƒ£ LLM CONVERSATION MEMORY")
    print("-" * 40)
    llm_demo = LLMContextDemo()
    llm_demo.demonstrate_llm_context_evolution()
    
    # Demo 5: Context Sharing Patterns
    print("\n\n5ï¸âƒ£ CONTEXT SHARING PATTERNS")
    print("-" * 40)
    context_demo = ContextSharingDemo()
    context_demo.demonstrate_hierarchical_context()
    
    print("\n\nâœ… DEMO COMPLETE!")
    print("You now understand how memory and context flow through your multi-agent system.")


if __name__ == "__main__":
    run_memory_and_context_demo()

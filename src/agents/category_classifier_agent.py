"""
STEP 3: CATEGORY CLASSIFIER AGENT - MAIN CLASSIFICATION WITH VECTOR SEARCH

This agent performs the first level of classification, determining the main
category for each ticket using a combination of semantic search and LLM
classification. It leverages Qdrant vector database for efficient similarity matching.

KEY RESPONSIBILITIES:
1. Vector-Based Similarity Search: Use embeddings to find similar categories
2. LLM Classification: Use GPT-4 with few-shot examples for final decision
3. Confidence Scoring: Generate reliable confidence scores for classifications
4. Few-Shot Learning: Maintain and use relevant classification examples
5. Category Validation: Ensure classifications match the hierarchy

CLASSIFICATION PIPELINE:
Processed Text โ Embeddings โ Vector Search โ Top-K Categories โ LLM + Few-Shot โ Final Classification

DESIGN DECISIONS:
- Hybrid Approach: Combines vector similarity with LLM reasoning
- Qdrant Integration: Production-ready vector database for semantic search
- OpenAI Embeddings: High-quality text embeddings for Arabic text
- Few-Shot Learning: Dynamic example selection for improved accuracy
- Confidence Thresholds: Configurable confidence levels for quality control

VECTOR SEARCH STRATEGY:
- Embed category descriptions and examples in Qdrant
- Query with processed ticket text to find semantically similar categories
- Use top-5 candidates as context for LLM classification
- Combine embedding similarity with LLM reasoning for final decision

INTEGRATION POINTS:
- Qdrant Vector Database: Semantic search and similarity matching
- OpenAI Embeddings: Text-to-vector conversion for Arabic content
- CategoryLoader: Access to category hierarchy and metadata
- ArabicProcessingAgent: Uses processed and normalized text
"""

import asyncio
import json
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
import numpy as np

from qdrant_client import QdrantClient
from qdrant_client.http import models
from qdrant_client.http.models import Distance, VectorParams, PointStruct
from openai import AsyncOpenAI

from .base_agent import BaseAgent, BaseAgentConfig, AgentType
from ..models.ticket_state import TicketState
from ..models.entities import Category, ClassificationHierarchy


class CategoryClassifierAgent(BaseAgent):
    """
    Category Classifier Agent: Main category classification with vector search.
    
    Combines semantic similarity search using Qdrant with LLM-based classification
    to achieve high accuracy in determining the main category for each ticket.
    """
    
    def __init__(self, config: BaseAgentConfig, 
                 hierarchy: Optional[ClassificationHierarchy] = None,
                 qdrant_url: str = "http://localhost:6333",
                 collection_name: str = "itsm_categories"):
        super().__init__(config)
        
        self.hierarchy = hierarchy
        self.collection_name = collection_name
        self.qdrant_url = qdrant_url
        
        # Initialize Qdrant client
        self.qdrant_client = QdrantClient(url=qdrant_url)
        
        # Initialize OpenAI client for embeddings - with API key validation
        if not config.api_key:
            raise ValueError("OpenAI API key is required for embeddings")
        self.openai_client = AsyncOpenAI(api_key=config.api_key)
        
        # Classification parameters - get from config
        self.embedding_model = getattr(config, 'embedding_model', "text-embedding-3-small")
        self.top_k_candidates = getattr(config, 'top_k_candidates', 5)
        self.similarity_threshold = getattr(config, 'similarity_threshold', 0.5)
        
        # Few-shot examples cache
        self.few_shot_cache = {}
        
        # Add strict mode attributes (required for main.py integration)
        self.strict_mode = False
        self.classification_validator = None
        
        self.logger.info(f"Category Classifier initialized with Qdrant at {qdrant_url}")
        
        # Flag to track initialization status
        self._vector_collection_initialized = False
    
    @classmethod
    async def create(cls, config: BaseAgentConfig, 
                     hierarchy: Optional[ClassificationHierarchy] = None,
                     qdrant_url: str = "http://localhost:6333",
                     collection_name: str = "itsm_categories"):
        """
        Async factory method to properly initialize CategoryClassifierAgent.
        
        Args:
            config: Agent configuration
            hierarchy: Classification hierarchy
            qdrant_url: Qdrant server URL
            collection_name: Collection name for vectors
            
        Returns:
            Fully initialized CategoryClassifierAgent
        """
        instance = cls(config, hierarchy, qdrant_url, collection_name)
        await instance._initialize_vector_collection()
        return instance
    
    async def _initialize_vector_collection(self):
        """Initialize Qdrant collection for category vectors"""
        try:
            # Check if collection exists
            collections = self.qdrant_client.get_collections().collections
            collection_exists = any(col.name == self.collection_name for col in collections)
            
            if not collection_exists:
                # Create collection with appropriate vector size (1536 for text-embedding-3-small)
                self.qdrant_client.create_collection(
                    collection_name=self.collection_name,
                    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),
                )
                self.logger.info(f"Created Qdrant collection: {self.collection_name}")
                
                # Initialize with category data if hierarchy is available
                if self.hierarchy:
                    await self._populate_vector_collection()
            else:
                self.logger.info(f"Using existing Qdrant collection: {self.collection_name}")
            
            self._vector_collection_initialized = True
                
        except Exception as e:
            self.logger.error(f"Failed to initialize Qdrant collection: {e}")
            self._vector_collection_initialized = False
    
    async def _populate_vector_collection(self):
        """Populate Qdrant collection with category embeddings"""
        try:
            points = []
            point_id = 0
            
            for category_name, category in self.hierarchy.categories.items():
                # Create embeddings for category name and description
                category_text = f"{category.name} {category.description}"
                
                # Get embedding
                embedding = await self._get_embedding(category_text)
                
                if embedding:
                    # Create point for Qdrant
                    point = PointStruct(
                        id=point_id,
                        vector=embedding,
                        payload={
                            "category_name": category.name,
                            "category_description": category.description,
                            "subcategory_count": len(category.subcategories),
                            "keywords": list(category.keywords),
                            "type": "main_category"
                        }
                    )
                    points.append(point)
                    point_id += 1
                
                # Add subcategories as additional context
                for subcategory in category.subcategories.values():
                    subcategory_text = f"{subcategory.name} {subcategory.description}"
                    subcategory_embedding = await self._get_embedding(subcategory_text)
                    
                    if subcategory_embedding:
                        point = PointStruct(
                            id=point_id,
                            vector=subcategory_embedding,
                            payload={
                                "category_name": category.name,
                                "subcategory_name": subcategory.name,
                                "subcategory_description": subcategory.description,
                                "parent_category": category.name,
                                "type": "subcategory_context"
                            }
                        )
                        points.append(point)
                        point_id += 1
            
            # Upload points to Qdrant
            if points:
                self.qdrant_client.upsert(
                    collection_name=self.collection_name,
                    points=points
                )
                self.logger.info(f"Populated Qdrant with {len(points)} category embeddings")
            
        except Exception as e:
            self.logger.error(f"Failed to populate vector collection: {e}")
    
    async def _get_embedding(self, text: str) -> Optional[List[float]]:
        """Get OpenAI embedding for text"""
        try:
            response = await self.openai_client.embeddings.create(
                input=text,
                model=self.embedding_model
            )
            return response.data[0].embedding
        except Exception as e:
            self.logger.warning(f"Failed to get embedding for text: {e}")
            return None
    
    async def process(self, state: TicketState) -> TicketState:
        """
        Classify ticket into main category using vector search + LLM.
        
        Args:
            state: Ticket state with processed Arabic text
            
        Returns:
            Enhanced state with main category classification
        """
        self.logger.info(f"Starting category classification for ticket {state.ticket_id}")
        
        # Get processed text (should be available from Arabic agent)
        text = getattr(state, 'processed_text', None) or state.original_text
        
        if not text or not text.strip():
            raise ValueError("No text available for classification")
        
        # 1. Vector-based similarity search
        similar_categories = await self._find_similar_categories(text)
        
        # 2. LLM-based classification with context
        classification_result = await self._classify_with_llm(text, similar_categories)
        
        # 3. Validate and store results
        await self._validate_and_store_classification(state, classification_result, similar_categories)
        
        self.logger.info(f"Category classification complete: {classification_result.get('category', 'unknown')}")
        return state
    
    async def _find_similar_categories(self, text: str) -> List[Dict[str, Any]]:
        """Find similar categories using vector search"""
        try:
            # Check if Qdrant is properly initialized
            if not self.qdrant_client:
                self.logger.error("Qdrant client not initialized")
                return self._fallback_keyword_search(text)
            
            # Check if vector collection is initialized
            if not self._vector_collection_initialized:
                self.logger.warning("Vector collection not initialized, attempting to initialize...")
                await self._initialize_vector_collection()
                if not self._vector_collection_initialized:
                    return self._fallback_keyword_search(text)
            
            # Check collection exists
            try:
                collection_info = self.qdrant_client.get_collection(self.collection_name)
            except Exception:
                self.logger.warning("Collection not found, creating...")
                await self._initialize_vector_collection()
                if not self._vector_collection_initialized:
                    return self._fallback_keyword_search(text)
            
            # Get embedding for the input text
            query_embedding = await self._get_embedding(text)
            
            if not query_embedding:
                self.logger.warning("Failed to get embedding for query text")
                return self._fallback_keyword_search(text)
            
            # Search in Qdrant
            search_results = self.qdrant_client.search(
                collection_name=self.collection_name,
                query_vector=query_embedding,
                limit=self.top_k_candidates * 2,  # Get more results to filter
                score_threshold=self.similarity_threshold
            )
            
            # Process results and group by main category
            category_scores = {}
            
            for result in search_results:
                category_name = result.payload["category_name"]
                score = result.score
                
                if category_name in category_scores:
                    # Take the best score for each category
                    category_scores[category_name] = max(category_scores[category_name], score)
                else:
                    category_scores[category_name] = score
            
            # Sort by score and return top candidates
            sorted_categories = sorted(category_scores.items(), key=lambda x: x[1], reverse=True)
            
            similar_categories = []
            for category_name, score in sorted_categories[:self.top_k_candidates]:
                if self.hierarchy and category_name in self.hierarchy.categories:
                    category = self.hierarchy.categories[category_name]
                    similar_categories.append({
                        "name": category_name,
                        "description": category.description,
                        "similarity_score": score,
                        "subcategory_count": len(category.subcategories),
                        "keywords": list(category.keywords)
                    })
            
            self.logger.debug(f"Found {len(similar_categories)} similar categories")
            return similar_categories
            
        except Exception as e:
            self.logger.error(f"Vector search failed: {e}")
            return self._fallback_keyword_search(text)
    
    def _fallback_keyword_search(self, text: str) -> List[Dict[str, Any]]:
        """Fallback keyword-based search when vector search fails"""
        if not self.hierarchy:
            return []
        
        # Simple keyword matching as fallback
        text_lower = text.lower()
        matches = []
        
        for category_name, category in self.hierarchy.categories.items():
            score = 0
            
            # Check category name
            if category_name.lower() in text_lower:
                score += 0.8
            
            # Check keywords
            for keyword in category.keywords:
                if keyword.lower() in text_lower:
                    score += 0.3
            
            if score > 0:
                matches.append({
                    "name": category_name,
                    "description": category.description,
                    "similarity_score": min(score, 1.0),
                    "subcategory_count": len(category.subcategories),
                    "keywords": list(category.keywords),
                    "search_method": "keyword_fallback"
                })
        
        # Sort by score and return top candidates
        matches.sort(key=lambda x: x["similarity_score"], reverse=True)
        return matches[:self.top_k_candidates]
    
    async def _classify_with_llm(self, text: str, similar_categories: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Classify using LLM with similar categories as context"""
        
        if not self.llm:
            raise ValueError("LLM not available for classification")
        
        # Get exact category names from hierarchy
        valid_categories = list(self.hierarchy.categories.keys()) if self.hierarchy else []
        
        # Build classification prompt with EXACT categories
        prompt = self._build_strict_classification_prompt(text, similar_categories, valid_categories)
        
        try:
            from langchain_core.messages import HumanMessage, SystemMessage
            
            system_message = SystemMessage(content=f"""
            ุฃูุช ุฎุจูุฑ ูู ุชุตููู ุชุฐุงูุฑ ุงูุฏุนู ุงูุชููู ูุฃูุธูุฉ ุงููุนูููุงุช.
            
            ููู ุฌุฏุงู: ูุฌุจ ุนููู ุงุฎุชูุงุฑ ูุฆุฉ ูู ุงููุงุฆูุฉ ุงููุญุฏุฏุฉ ููุท. ูุง ุชุฎุชุฑุน ูุฆุงุช ุฌุฏูุฏุฉ.
            
            ุงููุฆุงุช ุงููุชุงุญุฉ ููุท ูู:
            {', '.join(valid_categories)}
            
            ุงุณุชุฎุฏู Chain-of-Thought reasoning:
            1. ุฃููุงูุ ุงูุฑุฃ ุงููุต ูุญุฏุฏ ุงููููุงุช ุงูููุชุงุญูุฉ
            2. ุซุงููุงูุ ูุงุฑู ูุน ุงููุฆุงุช ุงููุชุงุญุฉ
            3. ุซุงูุซุงูุ ุงุฎุชุฑ ุงููุฆุฉ ุงูุฃูุณุจ ุจูุงุกู ุนูู ุงูุชุญููู
            
            ุฃุฌุจ ุจุตูุบุฉ JSON ุจุงูุถุจุท ููุง ููู:
            {{"category": "ุงุณู ุงููุฆุฉ ูู ุงููุงุฆูุฉ", "confidence": 0.95, "reasoning": "ุณุจุจ ุงูุงุฎุชูุงุฑ ูุน ุฎุทูุงุช ุงูุชูููุฑ", "chain_of_thought": "ุฃููุงู: ... ุซุงููุงู: ... ุซุงูุซุงู: ..."}}
            """)
            
            human_message = HumanMessage(content=prompt)
            
            response = await self._safe_llm_call([system_message, human_message])
            
            # Parse JSON response
            try:
                result = json.loads(response.content)
                
                # STRICT validation - must be exact match
                if result.get("category") not in valid_categories:
                    # Find the most similar valid category from the similar_categories list
                    if similar_categories and similar_categories[0]["name"] in valid_categories:
                        result["category"] = similar_categories[0]["name"]
                        result["confidence"] = similar_categories[0]["similarity_score"]
                        result["reasoning"] = "Corrected to valid category from similarity search"
                    else:
                        # Default to first valid category if nothing matches
                        result["category"] = valid_categories[0] if valid_categories else "ุบูุฑ ูุญุฏุฏ"
                        result["confidence"] = 0.3
                        result["reasoning"] = "No valid category match found"
                
                # Add metadata
                result["classification_method"] = "llm_with_vector_context_strict"
                result["similar_categories_used"] = len(similar_categories)
                
                return result
                
            except json.JSONDecodeError as e:
                self.logger.warning(f"Failed to parse LLM response as JSON: {e}")
                # Fallback to highest similarity category
                if similar_categories and similar_categories[0]["name"] in valid_categories:
                    return {
                        "category": similar_categories[0]["name"],
                        "confidence": similar_categories[0]["similarity_score"],
                        "reasoning": "Fallback to highest similarity match",
                        "classification_method": "vector_similarity_fallback"
                    }
                else:
                    return {
                        "category": valid_categories[0] if valid_categories else "ุบูุฑ ูุญุฏุฏ",
                        "confidence": 0.1,
                        "reasoning": "Fallback to first valid category",
                        "classification_method": "fallback_unknown"
                    }
                
        except Exception as e:
            self.logger.error(f"LLM classification failed: {e}")
            
            # Fallback to highest similarity category
            if similar_categories and similar_categories[0]["name"] in valid_categories:
                return {
                    "category": similar_categories[0]["name"],
                    "confidence": similar_categories[0]["similarity_score"],
                    "reasoning": "Fallback to highest similarity match",
                    "classification_method": "vector_similarity_fallback"
                }
            else:
                return {
                    "category": valid_categories[0] if valid_categories else "ุบูุฑ ูุญุฏุฏ",
                    "confidence": 0.1,
                    "reasoning": "No similar categories found",
                    "classification_method": "fallback_unknown"
                }
    
    def _build_strict_classification_prompt(self, text: str, similar_categories: List[Dict[str, Any]], 
                                           valid_categories: List[str]) -> str:
        """Build classification prompt with strict category enforcement and better context"""
        
        # Check for priority payment context first
        payment_priority = self._check_payment_priority_context(text)
        if payment_priority:
            return self._build_payment_priority_prompt(text, payment_priority, valid_categories)
        
        # Enhanced decision tree guidance based on comprehensive error analysis
        classification_guidance = {
            "ุงูุชุณุฌูู": [
                "- ุฅุฐุง ูุงู ุงููุต ุนู: ุฅูุดุงุก ุญุณุงุจ ุฌุฏูุฏุ ุงูุชุญูู ูู ุงูุณุฌู ุงูุชุฌุงุฑูุ ูุดุงูู ุจุนุฏ ุงูุชุณุฌูู",
                "- ูููุงุช ููุชุงุญูุฉ: ุชุณุฌููุ ุณุฌู ุชุฌุงุฑูุ ุฅูุดุงุก ุญุณุงุจุ ุชุงุฑูุฎ ุงูุงูุชูุงุก ุบูุฑ ุตุญูุญ",
                "- ุชุฑูุฒ ุนูู: ุนูููุฉ ุงูุชุณุฌูู ุงูุฃููู ูููุณ ุชุญุฏูุซ ุงูุจูุงูุงุช ุงููุงุญู",
                "- ูุซุงู: 'ุนูุฏ ุชุณุฌูู ุงูููุดุงุฉ ูุงุถุงูุฉ ุจูุงูุงุชูุง' = ุงูุชุณุฌูู (ูููุณ ุจูุงูุงุช ุงูููุดุฃุฉ)",
                "- ๐ฅ ูุงุนุฏุฉ ุญุงุณูุฉ: 'ุจุนุฏ ุชุณุฌูู ุฏุฎูู ูุงุณุชููุงู ุงูุจูุงูุงุช ุธูุฑ ุงู ุงูุดุฑูุฉ ูุณุฌูุฉ' = ุงูุชุณุฌูู (ุงูุชุญูู ูู ุงูุณุฌู)",
                "- ุฃู ูุดููุฉ ุชุญุฏุซ 'ุฃุซูุงุก' ุฃู 'ุจุนุฏ' ุงูุชุณุฌูู ุงูุฃููู = ุงูุชุณุฌูู ูููุณ ุจูุงูุงุช ุงูููุดุฃุฉ"
            ],
            "ุชุณุฌูู ุงูุฏุฎูู": [
                "- ุฅุฐุง ูุงู ุงููุต ุนู: ูุดุงูู ุงูุฏุฎูู ููููุตุฉุ ูููุฉ ุงููุฑูุฑุ ูุณูุช ูููุฉ ุงููุฑูุฑ",
                "- ูููุงุช ููุชุงุญูุฉ: ุฏุฎููุ ููุฌููุ ูููุฉ ูุฑูุฑุ ูุง ุฃุณุชุทูุน ุงูุฏุฎููุ ุงุณุชุนุงุฏุฉ ูููุฉ ุงููุฑูุฑ"
            ],
            "ุจูุงูุงุช ุงูููุดุฃุฉ": [
                "- ุฅุฐุง ูุงู ุงููุต ุนู: ุชุญุฏูุซ ุจูุงูุงุช ุงูุดุฑูุฉุ ุชุบููุฑ ุถุจุงุท ุงูุงุชุตุงูุ ุชุนุฏูู ุงููุนูููุงุชุ ูุดุงูู ุงูุฅูููู",
                "- ูููุงุช ููุชุงุญูุฉ: ุจูุงูุงุช ุงูููุดุฃุฉุ ูุนูููุงุช ุงูุดุฑูุฉุ ุถุงุจุท ุงุชุตุงูุ ุงูููู ูููุถุ ุฅุดุนุงุฑ ุงูููู",
                "- ุชุฑูุฒ ุนูู: ุชุญุฏูุซ ุงูุจูุงูุงุช ุงูููุฌูุฏุฉ ูููุณ ุงูุชุณุฌูู ุงูุฃููู",
                "- โ๏ธ ูุง ุชุฎุชุงุฑ ูุฐู ุงููุฆุฉ ุฅุฐุง ูุงู ุงููุต ุนู ูุดุงูู ุงูุชุณุฌูู ุงูุฃููู ุฃู ุงูุชุญูู ูู ุงูุณุฌู ุงูุชุฌุงุฑู",
                "- ๐ฅ ูุงุนุฏุฉ ูููุฉ: ุฅุฐุง ุฐููุฑ 'ุชุณุฌูู' ุฃู 'ุฅูุดุงุก ุญุณุงุจ' = ุงูุชุณุฌูู ูููุณ ุจูุงูุงุช ุงูููุดุฃุฉ"
            ],
            "ุงูุฅุฑุณุงููุฉ": [
                "- ุฅุฐุง ูุงู ุงููุต ุนู: ุดูุงุฏุงุช ุงูุฅุฑุณุงููุฉุ ุญุงูุฉ ุทูุจ ุงูุฅุฑุณุงููุฉุ ูุดุงูู ุฅุตุฏุงุฑ ุงูุดูุงุฏุฉ (ุจุฏูู ุฐูุฑ ูุดุงูู ุงูุฏูุน)",
                "- ูููุงุช ููุชุงุญูุฉ: ุฅุฑุณุงููุฉุ ุดูุงุฏุฉ ุฅุฑุณุงููุฉุ ุญุงูุฉ ุงูุทูุจุ ูู ุชุธูุฑ ุงูุดูุงุฏุฉุ ููุฏููุงุชุ ุฅุตุฏุงุฑ ุดูุงุฏุฉ",
                "- โ๏ธ ุฅุฐุง ุฐููุฑ 'ุณุฏุงุฏ ูุงุชูุฑุฉ' + ูุดููุฉ ูู ุงูุฏูุน = ุงููุฏููุนุงุช ูููุณ ุงูุฅุฑุณุงููุฉ",
                "- ๐ฅ ูุงุนุฏุฉ ูููุฉ: 'ุฎุทุฃ ูู ุฅุตุฏุงุฑ ุดูุงุฏุฉ ุฅุฑุณุงููุฉ' = ุงูุฅุฑุณุงููุฉ (ูุดููุฉ ุชูููุฉ)",
                "- ูุซุงู: 'ุดุงุดุฉ ุณูุฏุงุก ุนูุฏ ุฅุตุฏุงุฑ ุดูุงุฏุฉ ุฅุฑุณุงููุฉ' = ุงูุฅุฑุณุงููุฉ"
            ],
            "ุงููุฏููุนุงุช": [
                "- ุฅุฐุง ูุงู ุงููุต ุนู: ูุดุงูู ุงูุฏูุนุ ุงูุณุฏุงุฏ ูู ููุนูุณุ ุนุฏู ูุฏุฑุฉ ุนูู ุงูุฏูุนุ ูุดุงูู ุงูููุงุชูุฑ",
                "- ูููุงุช ููุชุงุญูุฉ: ุณุฏุงุฏุ ุฏูุนุ ูุงุชูุฑุฉุ ูู ููุนูุณุ ุฎุตู ุงููุจูุบุ ุงูุชุธุงุฑ ุงูุณุฏุงุฏุ ูุฏููุนุ ูุณุฏุฏ",
                "- ๐ฅ ูุงุนุฏุฉ ูููุฉ: 'ุชู ุณุฏุงุฏ ูุงุชูุฑุฉ X ููู ุชุธูุฑ' = ูุดููุฉ ุฏูุน = ุงููุฏููุนุงุช",
                "- ูุซุงู: 'ุชู ุณุฏุงุฏ ูุงุชูุฑุฉ ุดูุงุฏุฉ ุงุฑุณุงููุฉ ููู ุชุธูุฑ ุงูุดูุงุฏุฉ' = ุงููุฏููุนุงุช",
                "- ๐จ ูุฐู ุงููุฆุฉ ููุง ุฃููููุฉ ุนุงููุฉ: ุฅุฐุง ุฐููุฑ ุฃู ุณูุงู ุฏูุน ูุน ูุดููุฉ = ุงููุฏููุนุงุช"
            ],
            "ุงูุดูุงุฏุงุช ุงูุตุงุฏุฑุฉ ูู ุงูููุฆุฉ": [
                "- ุฅุฐุง ูุงู ุงููุต ุนู: ุดูุงุฏุงุช ุนุงูุฉ ุตุงุฏุฑุฉ ูู ุงูููุฆุฉ (ูููุณ ุดูุงุฏุงุช ุฅุฑุณุงููุฉ ูุญุฏุฏุฉ)",
                "- ูููุงุช ููุชุงุญูุฉ: ุดูุงุฏุฉ ุนุงูุฉุ ุดูุงุฏุฉ ูู ุงูููุฆุฉุ ุฅุตุฏุงุฑ ุดูุงุฏุฉ (ุจุฏูู ุฐูุฑ ุฅุฑุณุงููุฉ)",
                "- โ๏ธ ูุง ุชุฎุชุงุฑ ูุฐู ุงููุฆุฉ ุฅุฐุง ุฐููุฑ 'ุดูุงุฏุฉ ุฅุฑุณุงููุฉ' = ุงูุฅุฑุณุงููุฉ",
                "- โ๏ธ ูุง ุชุฎุชุงุฑ ูุฐู ุงููุฆุฉ ุฅุฐุง ุฐููุฑ 'ูุทุงุจูุฉ COC' = ูุทุงุจูุฉ ููุชุฌ COC"
            ],
            "ูุฆุฉ ุงููุณูุฌ": [
                "- ุฅุฐุง ูุงู ุงููุต ูุฐูุฑ ุตุฑุงุญุฉ 'ูุฆุฉ ุงููุณูุฌ' ุฃู 'ุงููุณูุญ'",
                "- ูููุงุช ููุชุงุญูุฉ: ูุฆุฉ ุงููุณูุฌุ ุงููุณูุญุ CA-",
                "- ูุซุงู: 'ูู ูุชู ุนูุณ ุงูุณุฏุงุฏ ูุทูุจ ูุฆุฉ ุงููุณูุญ' = ูุฆุฉ ุงููุณูุฌ"
            ]
        }
    
    def _check_payment_priority_context(self, text: str) -> Optional[str]:
        """Check if text has payment context that should override other classifications"""
        text_lower = text.lower()
        
        # High priority payment indicators - these should force ุงููุฏููุนุงุช classification
        payment_priority_patterns = [
            "ุชู ุณุฏุงุฏ ูุงุชูุฑุฉ.*ูู ุชุธูุฑ",
            "ุณุฏุงุฏ.*ูุงุชูุฑุฉ.*ูู.*ููุนูุณ",
            "ุจุนุฏ ุณุฏุงุฏ.*ูุง ุชูุนูุณ",
            "ุชู ุณุฏุงุฏ.*ุญุงูุฉ ุงูุทูุจ.*ุงูุชุธุงุฑ",
            "ูุงุชูุฑุฉ.*ูุณุฏุฏุฉ.*ูู ุชุธูุฑ",
            "ุฎุตู ุงููุจูุบ.*ูู.*ููุนูุณ",
            "ุณุฏุฏ.*ุงููุจูุบ.*ูู.*ูุชุญุฏุซ",
            "ูู ูุชู ุนูุณ ุงูุณุฏุงุฏ",
            "ูุฏููุน.*ูู ุชุธูุฑ",
            "ุณุฏุงุฏ.*ูู ูุชู.*ุนูุณ",
            "ุชู ุณุฏุงุฏ.*ูุน ุงูุนูู",  # "payment made but..." pattern
            "payment.*not.*reflecting",
            "unable.*payment.*portal"
        ]
        
        import re
        for pattern in payment_priority_patterns:
            if re.search(pattern, text_lower):
                return "payment_reflection_issue"
        
        # Medium priority payment context - but exclude technical generation issues
        payment_keywords = ["ุณุฏุงุฏ", "ูุงุชูุฑุฉ", "ุฏูุน", "ูุณุฏุฏ", "ูุฏููุน", "payment"]
        problem_keywords = ["ูู ุชุธูุฑ", "ูู ููุนูุณ", "ูุนูู", "ุงูุชุธุงุฑ ุงูุณุฏุงุฏ", "ูุดููุฉ"]
        
        # Exclude if it's clearly about invoice/certificate GENERATION (not payment issues)
        generation_exclusions = [
            "ุฅูุดุงุก ูุงุชูุฑุฉ.*ุฎุทุฃ",  # Error creating invoice (technical issue)
            "ุงุตุฏุงุฑ ูุงุชูุฑุฉ.*ุฎุทุฃ",   # Error generating invoice (technical issue) 
            "ุดุงุดุฉ.*ุจูุถุงุก.*ูุงุชูุฑุฉ", # White screen when generating invoice
            "ูุงุชูุฑุฉ.*ุดุงุดุฉ.*ุณูุฏุงุก", # Black screen when generating invoice
            "error.*creating.*invoice",
            "unable.*create.*invoice"
        ]
        
        # If it's clearly a technical generation issue, don't treat as payment problem
        for exclusion in generation_exclusions:
            if re.search(exclusion, text_lower):
                return None
        
        has_payment = any(keyword in text_lower for keyword in payment_keywords)
        has_problem = any(keyword in text_lower for keyword in problem_keywords)
        
        if has_payment and has_problem:
            return "payment_general_issue"
        
        return None
    
    def _build_payment_priority_prompt(self, text: str, payment_type: str, valid_categories: List[str]) -> str:
        """Build specialized prompt for payment-related issues"""
        
        if "ุงููุฏููุนุงุช" not in valid_categories:
            # Fallback to normal prompt if payment category not available
            return self._build_standard_prompt(text, valid_categories)
        
        payment_examples = {
            "payment_reflection_issue": [
                "ุชู ุณุฏุงุฏ ูุงุชูุฑุฉ ุดูุงุฏุฉ ุงุฑุณุงููุฉ ููู ุชุธูุฑ ุงูุดูุงุฏุฉ",
                "ุจุนุฏ ุณุฏุงุฏ ุงููุงุชูุฑุฉ ูุง ุชูุนูุณ ุญุงูุฉ ุงูุทูุจ", 
                "ูู ูุชู ุนูุณ ุงูุณุฏุงุฏ ูุทูุจ ูุฆุฉ ุงููุณูุญ",
                "ูุงุชูุฑุฉ ูุณุฏุฏุฉ ููู ุญุงูุฉ ุงูุทูุจ ุจุงูุชุธุงุฑ ุงูุณุฏุงุฏ"
            ],
            "payment_general_issue": [
                "ูุง ุฃุณุชุทูุน ุฏูุน ุฑุณูู ุงูุดูุงุฏุฉ",
                "ูุดููุฉ ูู ุฅูุดุงุก ูุงุชูุฑุฉ ููุทูุจ",
                "ุนูุฏ ูุญุงููุฉ ุงูุฏูุน ูุธูุฑ ุฎุทุฃ"
            ]
        }
        
        return f"""
๐จ **ูุดู ุณูุงู ุฏูุน ุฐู ุฃููููุฉ ุนุงููุฉ** ๐จ

ุงููุต ุงููุทููุจ ุชุตูููู: {text}

ุชู ูุดู ุณูุงู ุฏูุน ูู ุงููุต. ูุฐุง ูุนูู ุฃู ุงููุดููุฉ ุงูุฃุณุงุณูุฉ ุชุชุนูู ุจุงููุฏููุนุงุช ุญุชู ูู ุฐููุฑุช ุฎุฏูุงุช ุฃุฎุฑู.

๐ฅ **ูุงุนุฏุฉ ุงูุฃููููุฉ**: 
ุฅุฐุง ูุงู ุงููุต ูุญุชูู ุนูู ูุดููุฉ ูู ุงูุฏูุน ุฃู ุงูุณุฏุงุฏุ ูุงูุชุตููู ูุฌุจ ุฃู ูููู "ุงููุฏููุนุงุช" ุญุชู ูู ุฐููุฑุช ุฎุฏูุงุช ุฃุฎุฑู ูุซู ุงูุฅุฑุณุงููุฉ ุฃู ุงูุดูุงุฏุงุช.

๐ **ุฃูุซูุฉ ููุงุซูุฉ**:
{chr(10).join(f'- {example}' for example in payment_examples.get(payment_type, []))}

๐ฏ **ุงููุฆุงุช ุงููุชุงุญุฉ**:
{chr(10).join(f'{i+1}. {cat}' for i, cat in enumerate(valid_categories))}

โก **ุงูุชุตููู ุงููุทููุจ**: ุงููุฏููุนุงุช (ุฅูุง ุฅุฐุง ูุงู ููุงู ุณุจุจ ุงุณุชุซูุงุฆู)

ุฃุฌุจ ุจุตูุบุฉ JSON:
{{"category": "ุงููุฏููุนุงุช", "confidence": 0.95, "reasoning": "ูุดู ุณูุงู ุฏูุน ุฐู ุฃููููุฉ - {payment_type}"}}
"""
    
    def _build_standard_prompt(self, text: str, valid_categories: List[str]) -> str:
        """Build standard classification prompt when no priority context detected"""
        
        # Enhanced decision tree guidance based on comprehensive error analysis
        classification_guidance = {
            "ุงูุชุณุฌูู": [
                "- ุฅุฐุง ูุงู ุงููุต ุนู: ุฅูุดุงุก ุญุณุงุจ ุฌุฏูุฏุ ุงูุชุญูู ูู ุงูุณุฌู ุงูุชุฌุงุฑูุ ูุดุงูู ุจุนุฏ ุงูุชุณุฌูู",
                "- ูููุงุช ููุชุงุญูุฉ: ุชุณุฌููุ ุณุฌู ุชุฌุงุฑูุ ุฅูุดุงุก ุญุณุงุจุ ุชุงุฑูุฎ ุงูุงูุชูุงุก ุบูุฑ ุตุญูุญ",
                "- ุชุฑูุฒ ุนูู: ุนูููุฉ ุงูุชุณุฌูู ุงูุฃููู ูููุณ ุชุญุฏูุซ ุงูุจูุงูุงุช ุงููุงุญู",
                "- ูุซุงู: 'ุนูุฏ ุชุณุฌูู ุงูููุดุงุฉ ูุงุถุงูุฉ ุจูุงูุงุชูุง' = ุงูุชุณุฌูู (ูููุณ ุจูุงูุงุช ุงูููุดุฃุฉ)",
                "- ๐ฅ ูุงุนุฏุฉ ุญุงุณูุฉ: 'ุจุนุฏ ุชุณุฌูู ุฏุฎูู ูุงุณุชููุงู ุงูุจูุงูุงุช ุธูุฑ ุงู ุงูุดุฑูุฉ ูุณุฌูุฉ' = ุงูุชุณุฌูู (ุงูุชุญูู ูู ุงูุณุฌู)",
                "- ุฃู ูุดููุฉ ุชุญุฏุซ 'ุฃุซูุงุก' ุฃู 'ุจุนุฏ' ุงูุชุณุฌูู ุงูุฃููู = ุงูุชุณุฌูู ูููุณ ุจูุงูุงุช ุงูููุดุฃุฉ"
            ],
            "ุชุณุฌูู ุงูุฏุฎูู": [
                "- ุฅุฐุง ูุงู ุงููุต ุนู: ูุดุงูู ุงูุฏุฎูู ููููุตุฉุ ูููุฉ ุงููุฑูุฑุ ูุณูุช ูููุฉ ุงููุฑูุฑ",
                "- ูููุงุช ููุชุงุญูุฉ: ุฏุฎููุ ููุฌููุ ูููุฉ ูุฑูุฑุ ูุง ุฃุณุชุทูุน ุงูุฏุฎููุ ุงุณุชุนุงุฏุฉ ูููุฉ ุงููุฑูุฑ"
            ],
            "ุจูุงูุงุช ุงูููุดุฃุฉ": [
                "- ุฅุฐุง ูุงู ุงููุต ุนู: ุชุญุฏูุซ ุจูุงูุงุช ุงูุดุฑูุฉุ ุชุบููุฑ ุถุจุงุท ุงูุงุชุตุงูุ ุชุนุฏูู ุงููุนูููุงุชุ ูุดุงูู ุงูุฅูููู",
                "- ูููุงุช ููุชุงุญูุฉ: ุจูุงูุงุช ุงูููุดุฃุฉุ ูุนูููุงุช ุงูุดุฑูุฉุ ุถุงุจุท ุงุชุตุงูุ ุงูููู ูููุถุ ุฅุดุนุงุฑ ุงูููู",
                "- ุชุฑูุฒ ุนูู: ุชุญุฏูุซ ุงูุจูุงูุงุช ุงูููุฌูุฏุฉ ูููุณ ุงูุชุณุฌูู ุงูุฃููู",
                "- โ๏ธ ูุง ุชุฎุชุงุฑ ูุฐู ุงููุฆุฉ ุฅุฐุง ูุงู ุงููุต ุนู ูุดุงูู ุงูุชุณุฌูู ุงูุฃููู ุฃู ุงูุชุญูู ูู ุงูุณุฌู ุงูุชุฌุงุฑู",
                "- ๐ฅ ูุงุนุฏุฉ ูููุฉ: ุฅุฐุง ุฐููุฑ 'ุชุณุฌูู' ุฃู 'ุฅูุดุงุก ุญุณุงุจ' = ุงูุชุณุฌูู ูููุณ ุจูุงูุงุช ุงูููุดุฃุฉ"
            ],
            "ุงูุฅุฑุณุงููุฉ": [
                "- ุฅุฐุง ูุงู ุงููุต ุนู: ุดูุงุฏุงุช ุงูุฅุฑุณุงููุฉุ ุญุงูุฉ ุทูุจ ุงูุฅุฑุณุงููุฉุ ูุดุงูู ุฅุตุฏุงุฑ ุงูุดูุงุฏุฉ (ุจุฏูู ุฐูุฑ ูุดุงูู ุงูุฏูุน)",
                "- ูููุงุช ููุชุงุญูุฉ: ุฅุฑุณุงููุฉุ ุดูุงุฏุฉ ุฅุฑุณุงููุฉุ ุญุงูุฉ ุงูุทูุจุ ูู ุชุธูุฑ ุงูุดูุงุฏุฉุ ููุฏููุงุชุ ุฅุตุฏุงุฑ ุดูุงุฏุฉ",
                "- โ๏ธ ุฅุฐุง ุฐููุฑ 'ุณุฏุงุฏ ูุงุชูุฑุฉ' + ูุดููุฉ ูู ุงูุฏูุน = ุงููุฏููุนุงุช ูููุณ ุงูุฅุฑุณุงููุฉ",
                "- ๐ฅ ูุงุนุฏุฉ ูููุฉ: 'ุฎุทุฃ ูู ุฅุตุฏุงุฑ ุดูุงุฏุฉ ุฅุฑุณุงููุฉ' = ุงูุฅุฑุณุงููุฉ (ูุดููุฉ ุชูููุฉ)",
                "- ูุซุงู: 'ุดุงุดุฉ ุณูุฏุงุก ุนูุฏ ุฅุตุฏุงุฑ ุดูุงุฏุฉ ุฅุฑุณุงููุฉ' = ุงูุฅุฑุณุงููุฉ"
            ],
            "ุงููุฏููุนุงุช": [
                "- ุฅุฐุง ูุงู ุงููุต ุนู: ูุดุงูู ุงูุฏูุนุ ุงูุณุฏุงุฏ ูู ููุนูุณุ ุนุฏู ูุฏุฑุฉ ุนูู ุงูุฏูุนุ ูุดุงูู ุงูููุงุชูุฑ",
                "- ูููุงุช ููุชุงุญูุฉ: ุณุฏุงุฏุ ุฏูุนุ ูุงุชูุฑุฉุ ูู ููุนูุณุ ุฎุตู ุงููุจูุบุ ุงูุชุธุงุฑ ุงูุณุฏุงุฏุ ูุฏููุนุ ูุณุฏุฏ",
                "- ๐ฅ ูุงุนุฏุฉ ูููุฉ: 'ุชู ุณุฏุงุฏ ูุงุชูุฑุฉ X ููู ุชุธูุฑ' = ูุดููุฉ ุฏูุน = ุงููุฏููุนุงุช",
                "- ูุซุงู: 'ุชู ุณุฏุงุฏ ูุงุชูุฑุฉ ุดูุงุฏุฉ ุงุฑุณุงููุฉ ููู ุชุธูุฑ ุงูุดูุงุฏุฉ' = ุงููุฏููุนุงุช",
                "- ๐จ ูุฐู ุงููุฆุฉ ููุง ุฃููููุฉ ุนุงููุฉ: ุฅุฐุง ุฐููุฑ ุฃู ุณูุงู ุฏูุน ูุน ูุดููุฉ = ุงููุฏููุนุงุช"
            ],
            "ุงูุดูุงุฏุงุช ุงูุตุงุฏุฑุฉ ูู ุงูููุฆุฉ": [
                "- ุฅุฐุง ูุงู ุงููุต ุนู: ุดูุงุฏุงุช ุนุงูุฉ ุตุงุฏุฑุฉ ูู ุงูููุฆุฉ (ูููุณ ุดูุงุฏุงุช ุฅุฑุณุงููุฉ ูุญุฏุฏุฉ)",
                "- ูููุงุช ููุชุงุญูุฉ: ุดูุงุฏุฉ ุนุงูุฉุ ุดูุงุฏุฉ ูู ุงูููุฆุฉุ ุฅุตุฏุงุฑ ุดูุงุฏุฉ (ุจุฏูู ุฐูุฑ ุฅุฑุณุงููุฉ)",
                "- โ๏ธ ูุง ุชุฎุชุงุฑ ูุฐู ุงููุฆุฉ ุฅุฐุง ุฐููุฑ 'ุดูุงุฏุฉ ุฅุฑุณุงููุฉ' = ุงูุฅุฑุณุงููุฉ",
                "- โ๏ธ ูุง ุชุฎุชุงุฑ ูุฐู ุงููุฆุฉ ุฅุฐุง ุฐููุฑ 'ูุทุงุจูุฉ COC' = ูุทุงุจูุฉ ููุชุฌ COC"
            ],
            "ูุฆุฉ ุงููุณูุฌ": [
                "- ุฅุฐุง ูุงู ุงููุต ูุฐูุฑ ุตุฑุงุญุฉ 'ูุฆุฉ ุงููุณูุฌ' ุฃู 'ุงููุณูุญ'",
                "- ูููุงุช ููุชุงุญูุฉ: ูุฆุฉ ุงููุณูุฌุ ุงููุณูุญุ CA-",
                "- ูุซุงู: 'ูู ูุชู ุนูุณ ุงูุณุฏุงุฏ ูุทูุจ ูุฆุฉ ุงููุณูุญ' = ูุฆุฉ ุงููุณูุฌ"
            ]
        }
        
        prompt_parts = [
            "ุฃูุช ุฎุจูุฑ ุชุตููู ุชุฐุงูุฑ ุงูุฏุนู ุงูููู ููุธุงู ุณุงุจุฑ. ุตูู ุงููุต ุงูุชุงูู ุฅูู ุฅุญุฏู ุงููุฆุงุช ุงููุญุฏุฏุฉ ููุท:",
            f"ุงููุต: {text}",
            "",
            "=== ุฏููู ุงูุชุตููู ุงูุฏููู ==="
        ]
        
        # Add specific guidance for top categories
        for category in valid_categories[:8]:  # Focus on top 8 most relevant
            if category in classification_guidance:
                prompt_parts.append(f"\n๐ {category}:")
                prompt_parts.extend(classification_guidance[category])
        
        prompt_parts.extend([
            "",
            "=== ููุงุนุฏ ุงูุชุตููู ุงููููุฉ ุฌุฏุงู ===",
            "๐ฅ ูุงุนุฏุฉ ุงูุฏูุน ูุงูุณุฏุงุฏ (ุฃููููุฉ ุนุงููุฉ):",
            "- ุฅุฐุง ุฐูุฑ ุงููุต 'ุณุฏุงุฏ ูุงุชูุฑุฉ' ุฃู 'ุฏูุน' ูุน ูุดููุฉ ูู ุนุฏู ุงูุนูุงุณ ุงูุฏูุน โ ุงููุฏููุนุงุช",
            "- ุฅุฐุง ุฐูุฑ ุงููุต 'ุชู ุณุฏุงุฏ ูุงุชูุฑุฉ X ููู ุชุธูุฑ' โ ุงููุฏููุนุงุช",
            "- ุฅุฐุง ุฐูุฑ ุงููุต 'ูู ูุชู ุนูุณ ุงูุณุฏุงุฏ' โ ุงููุฏููุนุงุช",
            "- ุฅุฐุง ุฐูุฑ ุงููุต 'ุจุนุฏ ุณุฏุงุฏ ุงููุงุชูุฑุฉ ูุง ุชูุนูุณ ุญุงูุฉ ุงูุทูุจ' โ ุงููุฏููุนุงุช",
            "- ุฅุฐุง ุฐูุฑ ุงููุต ูุดููุฉ ูู ุงูุฎุฏูุฉ ุจุฏูู ุฐูุฑ ุงูุฏูุน โ ุงูุฎุฏูุฉ ุงููุชุฃุซุฑุฉ",
            "",
            "๐ ูุงุนุฏุฉ ุงูุชุณุฌูู ููุงุจู ุชุญุฏูุซ ุงูุจูุงูุงุช:",
            "- 'ุชุณุฌูู ุงูููุดุงุฉ/ุงูุญุณุงุจ' + 'ุฅูุดุงุก/ุฌุฏูุฏ' โ ุงูุชุณุฌูู", 
            "- 'ุชุญุฏูุซ/ุชุนุฏูู' + 'ุจูุงูุงุช ููุฌูุฏุฉ' โ ุจูุงูุงุช ุงูููุดุฃุฉ",
            "- 'ุชุงุฑูุฎ ุงูุงูุชูุงุก ุบูุฑ ุตุญูุญ' ุฃุซูุงุก ุงูุชุณุฌูู โ ุงูุชุณุฌูู",
            "- ๐ฅ 'ุจุนุฏ ุชุณุฌูู ุฏุฎูู ูุงุณุชููุงู ุงูุจูุงูุงุช ุธูุฑ ุงู ุงูุดุฑูุฉ ูุณุฌูุฉ' โ ุงูุชุณุฌูู (ูุดููุฉ ูู ุงูุชุญูู)",
            "- ุฃู ูุดููุฉ ุชุญุฏุซ 'ุฃุซูุงุก' ุฃู 'ุจุนุฏ' ุนูููุฉ ุงูุชุณุฌูู ุงูุฃููู โ ุงูุชุณุฌูู",
            "",
            "๐ฆ ูุงุนุฏุฉ ุงูุฅุฑุณุงููุฉ ููุงุจู ุงูุดูุงุฏุงุช:",
            "- 'ุดูุงุฏุฉ ุฅุฑุณุงููุฉ' + ูุดููุฉ ุชูููุฉ ูู ุงูุฅุตุฏุงุฑ โ ุงูุฅุฑุณุงููุฉ",
            "- 'ุดุงุดุฉ ุณูุฏุงุก' ุฃู 'ุฎุทุฃ' ุนูุฏ ุฅุตุฏุงุฑ ุดูุงุฏุฉ ุฅุฑุณุงููุฉ โ ุงูุฅุฑุณุงููุฉ",
            "- ุดูุงุฏุงุช ุนุงูุฉ ุฃุฎุฑู ูู ุงูููุฆุฉ โ ุงูุดูุงุฏุงุช ุงูุตุงุฏุฑุฉ ูู ุงูููุฆุฉ",
            "",
            "๐ง ูุงุนุฏุฉ ูุดุงูู ุงูุฅูููู:",
            "- 'ูู ูุตู ุงูููู' ุฃู 'ูุดุงูู ุฅุดุนุงุฑุงุช' โ ุจูุงูุงุช ุงูููุดุฃุฉ",
            "- 'ุงูููู ูููุถ ุงูููุดุฃุฉ' โ ุจูุงูุงุช ุงูููุดุฃุฉ",
            "",
            "ุฃูุซูุฉ ุชุทุจูููุฉ ุญุงุณูุฉ:",
            "- 'ุชู ุณุฏุงุฏ ูุงุชูุฑุฉ ุดูุงุฏุฉ ุงุฑุณุงููุฉ ููู ุชุธูุฑ ุงูุดูุงุฏุฉ' โ ุงููุฏููุนุงุช (ูุดููุฉ ุฏูุน)",
            "- 'ุฎุทุฃ ูู ุฅุตุฏุงุฑ ุดูุงุฏุฉ ุฅุฑุณุงููุฉ' โ ุงูุฅุฑุณุงููุฉ (ูุดููุฉ ุชูููุฉ)",
            "- 'ุดุงุดุฉ ุณูุฏุงุก ุนูุฏ ุฅุตุฏุงุฑ ุดูุงุฏุฉ ุฅุฑุณุงููุฉ' โ ุงูุฅุฑุณุงููุฉ (ูุดููุฉ ุชูููุฉ)",
            "- 'ุนูุฏ ุชุณุฌูู ุงูููุดุงุฉ ูุงุถุงูุฉ ุจูุงูุงุชูุง ูุญุฏุซ ุฎุทุง' โ ุงูุชุณุฌูู", 
            "- 'ุจุนุฏ ุชุณุฌูู ุฏุฎูู ูุงุณุชููุงู ุงูุจูุงูุงุช ุธูุฑ ุงู ุงูุดุฑูุฉ ูุณุฌูุฉ' โ ุงูุชุณุฌูู",
            "- 'ูู ูุชู ุนูุณ ุงูุณุฏุงุฏ ูุทูุจ ูุฆุฉ ุงููุณูุญ' โ ุงููุฏููุนุงุช (ูุดููุฉ ุฏูุน)",
            "- 'ูุง ุฃุณุชุทูุน ุฏูุน ุฑุณูู ุงูุดูุงุฏุฉ' โ ุงููุฏููุนุงุช",
            "",
            "ุงููุฆุงุช ุงููุชุงุญุฉ ููุท (ุงุฎุชุฑ ูุงุญุฏุฉ ุจุงูุถุจุท ููุง ูู ููุชูุจุฉ):"
        ])
        
        # List all valid categories
        for i, category in enumerate(valid_categories, 1):
            prompt_parts.append(f"{i}. {category}")
        
        prompt_parts.extend([
            "",
            "ุชุฐูุฑ: ุงุฎุชุฑ ููุท ูู ุงููุฆุงุช ุงููุฐููุฑุฉ ุฃุนูุงู ุจุงูุถุจุท ููุง ูู ููุชูุจุฉ.",
            "ุฃุฌุจ ุจุตูุบุฉ JSON ููุท:",
            '{"category": "ุงุณู ุงููุฆุฉ", "confidence": 0.95, "reasoning": "ุณุจุจ ุงูุงุฎุชูุงุฑ ูุน ุงูุชุทุจูู ุงููุจุงุดุฑ ููููุงุนุฏ"}'
        ])
        
        return "\n".join(prompt_parts)
    
    def _build_standard_classification_prompt(self, text: str, similar_categories: List[Dict[str, Any]], 
                                              valid_categories: List[str]) -> str:
        """Build standard classification prompt when no priority context detected"""
        
        # Enhanced decision tree guidance based on comprehensive error analysis
        classification_guidance = {
            "ุงูุชุณุฌูู": [
                "- ุฅุฐุง ูุงู ุงููุต ุนู: ุฅูุดุงุก ุญุณุงุจ ุฌุฏูุฏุ ุงูุชุญูู ูู ุงูุณุฌู ุงูุชุฌุงุฑูุ ูุดุงูู ุจุนุฏ ุงูุชุณุฌูู",
                "- ูููุงุช ููุชุงุญูุฉ: ุชุณุฌููุ ุณุฌู ุชุฌุงุฑูุ ุฅูุดุงุก ุญุณุงุจุ ุชุงุฑูุฎ ุงูุงูุชูุงุก ุบูุฑ ุตุญูุญ",
                "- ุชุฑูุฒ ุนูู: ุนูููุฉ ุงูุชุณุฌูู ุงูุฃููู ูููุณ ุชุญุฏูุซ ุงูุจูุงูุงุช ุงููุงุญู",
                "- ูุซุงู: 'ุนูุฏ ุชุณุฌูู ุงูููุดุงุฉ ูุงุถุงูุฉ ุจูุงูุงุชูุง' = ุงูุชุณุฌูู (ูููุณ ุจูุงูุงุช ุงูููุดุฃุฉ)",
                "- ๐ฅ ูุงุนุฏุฉ ุญุงุณูุฉ: 'ุจุนุฏ ุชุณุฌูู ุฏุฎูู ูุงุณุชููุงู ุงูุจูุงูุงุช ุธูุฑ ุงู ุงูุดุฑูุฉ ูุณุฌูุฉ' = ุงูุชุณุฌูู (ุงูุชุญูู ูู ุงูุณุฌู)",
                "- ุฃู ูุดููุฉ ุชุญุฏุซ 'ุฃุซูุงุก' ุฃู 'ุจุนุฏ' ุงูุชุณุฌูู ุงูุฃููู = ุงูุชุณุฌูู ูููุณ ุจูุงูุงุช ุงูููุดุฃุฉ"
            ],
            "ุชุณุฌูู ุงูุฏุฎูู": [
                "- ุฅุฐุง ูุงู ุงููุต ุนู: ูุดุงูู ุงูุฏุฎูู ููููุตุฉุ ูููุฉ ุงููุฑูุฑุ ูุณูุช ูููุฉ ุงููุฑูุฑ",
                "- ูููุงุช ููุชุงุญูุฉ: ุฏุฎููุ ููุฌููุ ูููุฉ ูุฑูุฑุ ูุง ุฃุณุชุทูุน ุงูุฏุฎููุ ุงุณุชุนุงุฏุฉ ูููุฉ ุงููุฑูุฑ"
            ],
            "ุจูุงูุงุช ุงูููุดุฃุฉ": [
                "- ุฅุฐุง ูุงู ุงููุต ุนู: ุชุญุฏูุซ ุจูุงูุงุช ุงูุดุฑูุฉุ ุชุบููุฑ ุถุจุงุท ุงูุงุชุตุงูุ ุชุนุฏูู ุงููุนูููุงุชุ ูุดุงูู ุงูุฅูููู",
                "- ูููุงุช ููุชุงุญูุฉ: ุจูุงูุงุช ุงูููุดุฃุฉุ ูุนูููุงุช ุงูุดุฑูุฉุ ุถุงุจุท ุงุชุตุงูุ ุงูููู ูููุถุ ุฅุดุนุงุฑ ุงูููู",
                "- ุชุฑูุฒ ุนูู: ุชุญุฏูุซ ุงูุจูุงูุงุช ุงูููุฌูุฏุฉ ูููุณ ุงูุชุณุฌูู ุงูุฃููู",
                "- โ๏ธ ูุง ุชุฎุชุงุฑ ูุฐู ุงููุฆุฉ ุฅุฐุง ูุงู ุงููุต ุนู ูุดุงูู ุงูุชุณุฌูู ุงูุฃููู ุฃู ุงูุชุญูู ูู ุงูุณุฌู ุงูุชุฌุงุฑู",
                "- ๐ฅ ูุงุนุฏุฉ ูููุฉ: ุฅุฐุง ุฐููุฑ 'ุชุณุฌูู' ุฃู 'ุฅูุดุงุก ุญุณุงุจ' = ุงูุชุณุฌูู ูููุณ ุจูุงูุงุช ุงูููุดุฃุฉ"
            ],
            "ุงูุฅุฑุณุงููุฉ": [
                "- ุฅุฐุง ูุงู ุงููุต ุนู: ุดูุงุฏุงุช ุงูุฅุฑุณุงููุฉุ ุญุงูุฉ ุทูุจ ุงูุฅุฑุณุงููุฉุ ูุดุงูู ุฅุตุฏุงุฑ ุงูุดูุงุฏุฉ (ุจุฏูู ุฐูุฑ ูุดุงูู ุงูุฏูุน)",
                "- ูููุงุช ููุชุงุญูุฉ: ุฅุฑุณุงููุฉุ ุดูุงุฏุฉ ุฅุฑุณุงููุฉุ ุญุงูุฉ ุงูุทูุจุ ูู ุชุธูุฑ ุงูุดูุงุฏุฉุ ููุฏููุงุชุ ุฅุตุฏุงุฑ ุดูุงุฏุฉ",
                "- โ๏ธ ุฅุฐุง ุฐููุฑ 'ุณุฏุงุฏ ูุงุชูุฑุฉ' + ูุดููุฉ ูู ุงูุฏูุน = ุงููุฏููุนุงุช ูููุณ ุงูุฅุฑุณุงููุฉ",
                "- ๐ฅ ูุงุนุฏุฉ ูููุฉ: 'ุฎุทุฃ ูู ุฅุตุฏุงุฑ ุดูุงุฏุฉ ุฅุฑุณุงููุฉ' = ุงูุฅุฑุณุงููุฉ (ูุดููุฉ ุชูููุฉ)",
                "- ูุซุงู: 'ุดุงุดุฉ ุณูุฏุงุก ุนูุฏ ุฅุตุฏุงุฑ ุดูุงุฏุฉ ุฅุฑุณุงููุฉ' = ุงูุฅุฑุณุงููุฉ"
            ],
            "ุงููุฏููุนุงุช": [
                "- ุฅุฐุง ูุงู ุงููุต ุนู: ูุดุงูู ุงูุฏูุนุ ุงูุณุฏุงุฏ ูู ููุนูุณุ ุนุฏู ูุฏุฑุฉ ุนูู ุงูุฏูุนุ ูุดุงูู ุงูููุงุชูุฑ",
                "- ูููุงุช ููุชุงุญูุฉ: ุณุฏุงุฏุ ุฏูุนุ ูุงุชูุฑุฉุ ูู ููุนูุณุ ุฎุตู ุงููุจูุบุ ุงูุชุธุงุฑ ุงูุณุฏุงุฏุ ูุฏููุนุ ูุณุฏุฏ",
                "- ๐ฅ ูุงุนุฏุฉ ูููุฉ: 'ุชู ุณุฏุงุฏ ูุงุชูุฑุฉ X ููู ุชุธูุฑ' = ูุดููุฉ ุฏูุน = ุงููุฏููุนุงุช",
                "- ูุซุงู: 'ุชู ุณุฏุงุฏ ูุงุชูุฑุฉ ุดูุงุฏุฉ ุงุฑุณุงููุฉ ููู ุชุธูุฑ ุงูุดูุงุฏุฉ' = ุงููุฏููุนุงุช",
                "- ๐จ ูุฐู ุงููุฆุฉ ููุง ุฃููููุฉ ุนุงููุฉ: ุฅุฐุง ุฐููุฑ ุฃู ุณูุงู ุฏูุน ูุน ูุดููุฉ = ุงููุฏููุนุงุช"
            ],
            "ุงูุดูุงุฏุงุช ุงูุตุงุฏุฑุฉ ูู ุงูููุฆุฉ": [
                "- ุฅุฐุง ูุงู ุงููุต ุนู: ุดูุงุฏุงุช ุนุงูุฉ ุตุงุฏุฑุฉ ูู ุงูููุฆุฉ (ูููุณ ุดูุงุฏุงุช ุฅุฑุณุงููุฉ ูุญุฏุฏุฉ)",
                "- ูููุงุช ููุชุงุญูุฉ: ุดูุงุฏุฉ ุนุงูุฉุ ุดูุงุฏุฉ ูู ุงูููุฆุฉุ ุฅุตุฏุงุฑ ุดูุงุฏุฉ (ุจุฏูู ุฐูุฑ ุฅุฑุณุงููุฉ)",
                "- โ๏ธ ูุง ุชุฎุชุงุฑ ูุฐู ุงููุฆุฉ ุฅุฐุง ุฐููุฑ 'ุดูุงุฏุฉ ุฅุฑุณุงููุฉ' = ุงูุฅุฑุณุงููุฉ",
                "- โ๏ธ ูุง ุชุฎุชุงุฑ ูุฐู ุงููุฆุฉ ุฅุฐุง ุฐููุฑ 'ูุทุงุจูุฉ COC' = ูุทุงุจูุฉ ููุชุฌ COC"
            ],
            "ูุฆุฉ ุงููุณูุฌ": [
                "- ุฅุฐุง ูุงู ุงููุต ูุฐูุฑ ุตุฑุงุญุฉ 'ูุฆุฉ ุงููุณูุฌ' ุฃู 'ุงููุณูุญ'",
                "- ูููุงุช ููุชุงุญูุฉ: ูุฆุฉ ุงููุณูุฌุ ุงููุณูุญุ CA-",
                "- ูุซุงู: 'ูู ูุชู ุนูุณ ุงูุณุฏุงุฏ ูุทูุจ ูุฆุฉ ุงููุณูุญ' = ูุฆุฉ ุงููุณูุฌ"
            ]
        }
        
        prompt_parts = [
            "ุฃูุช ุฎุจูุฑ ุชุตููู ุชุฐุงูุฑ ุงูุฏุนู ุงูููู ููุธุงู ุณุงุจุฑ. ุตูู ุงููุต ุงูุชุงูู ุฅูู ุฅุญุฏู ุงููุฆุงุช ุงููุญุฏุฏุฉ ููุท:",
            f"ุงููุต: {text}",
            "",
            "=== ุฏููู ุงูุชุตููู ุงูุฏููู ==="
        ]
        
        # Add specific guidance for top categories
        for category in valid_categories[:8]:  # Focus on top 8 most relevant
            if category in classification_guidance:
                prompt_parts.append(f"\n๐ {category}:")
                prompt_parts.extend(classification_guidance[category])
        
        prompt_parts.extend([
            "",
            "=== ููุงุนุฏ ุงูุชุตููู ุงููููุฉ ุฌุฏุงู ===",
            "๐ฅ ูุงุนุฏุฉ ุงูุฏูุน ูุงูุณุฏุงุฏ (ุฃููููุฉ ุนุงููุฉ):",
            "- ุฅุฐุง ุฐูุฑ ุงููุต 'ุณุฏุงุฏ ูุงุชูุฑุฉ' ุฃู 'ุฏูุน' ูุน ูุดููุฉ ูู ุนุฏู ุงูุนูุงุณ ุงูุฏูุน โ ุงููุฏููุนุงุช",
            "- ุฅุฐุง ุฐูุฑ ุงููุต 'ุชู ุณุฏุงุฏ ูุงุชูุฑุฉ X ููู ุชุธูุฑ' โ ุงููุฏููุนุงุช",
            "- ุฅุฐุง ุฐูุฑ ุงููุต 'ูู ูุชู ุนูุณ ุงูุณุฏุงุฏ' โ ุงููุฏููุนุงุช",
            "- ุฅุฐุง ุฐูุฑ ุงููุต 'ุจุนุฏ ุณุฏุงุฏ ุงููุงุชูุฑุฉ ูุง ุชูุนูุณ ุญุงูุฉ ุงูุทูุจ' โ ุงููุฏููุนุงุช",
            "- ุฅุฐุง ุฐูุฑ ุงููุต ูุดููุฉ ูู ุงูุฎุฏูุฉ ุจุฏูู ุฐูุฑ ุงูุฏูุน โ ุงูุฎุฏูุฉ ุงููุชุฃุซุฑุฉ",
            "",
            "๐ ูุงุนุฏุฉ ุงูุชุณุฌูู ููุงุจู ุชุญุฏูุซ ุงูุจูุงูุงุช:",
            "- 'ุชุณุฌูู ุงูููุดุงุฉ/ุงูุญุณุงุจ' + 'ุฅูุดุงุก/ุฌุฏูุฏ' โ ุงูุชุณุฌูู", 
            "- 'ุชุญุฏูุซ/ุชุนุฏูู' + 'ุจูุงูุงุช ููุฌูุฏุฉ' โ ุจูุงูุงุช ุงูููุดุฃุฉ",
            "- 'ุชุงุฑูุฎ ุงูุงูุชูุงุก ุบูุฑ ุตุญูุญ' ุฃุซูุงุก ุงูุชุณุฌูู โ ุงูุชุณุฌูู",
            "- ๐ฅ 'ุจุนุฏ ุชุณุฌูู ุฏุฎูู ูุงุณุชููุงู ุงูุจูุงูุงุช ุธูุฑ ุงู ุงูุดุฑูุฉ ูุณุฌูุฉ' โ ุงูุชุณุฌูู (ูุดููุฉ ูู ุงูุชุญูู)",
            "- ุฃู ูุดููุฉ ุชุญุฏุซ 'ุฃุซูุงุก' ุฃู 'ุจุนุฏ' ุนูููุฉ ุงูุชุณุฌูู ุงูุฃููู โ ุงูุชุณุฌูู",
            "",
            "๐ฆ ูุงุนุฏุฉ ุงูุฅุฑุณุงููุฉ ููุงุจู ุงูุดูุงุฏุงุช:",
            "- 'ุดูุงุฏุฉ ุฅุฑุณุงููุฉ' + ูุดููุฉ ุชูููุฉ ูู ุงูุฅุตุฏุงุฑ โ ุงูุฅุฑุณุงููุฉ",
            "- 'ุดุงุดุฉ ุณูุฏุงุก' ุฃู 'ุฎุทุฃ' ุนูุฏ ุฅุตุฏุงุฑ ุดูุงุฏุฉ ุฅุฑุณุงููุฉ โ ุงูุฅุฑุณุงููุฉ",
            "- ุดูุงุฏุงุช ุนุงูุฉ ุฃุฎุฑู ูู ุงูููุฆุฉ โ ุงูุดูุงุฏุงุช ุงูุตุงุฏุฑุฉ ูู ุงูููุฆุฉ",
            "",
            "๐ง ูุงุนุฏุฉ ูุดุงูู ุงูุฅูููู:",
            "- 'ูู ูุตู ุงูููู' ุฃู 'ูุดุงูู ุฅุดุนุงุฑุงุช' โ ุจูุงูุงุช ุงูููุดุฃุฉ",
            "- 'ุงูููู ูููุถ ุงูููุดุฃุฉ' โ ุจูุงูุงุช ุงูููุดุฃุฉ",
            "",
            "ุฃูุซูุฉ ุชุทุจูููุฉ ุญุงุณูุฉ:",
            "- 'ุชู ุณุฏุงุฏ ูุงุชูุฑุฉ ุดูุงุฏุฉ ุงุฑุณุงููุฉ ููู ุชุธูุฑ ุงูุดูุงุฏุฉ' โ ุงููุฏููุนุงุช (ูุดููุฉ ุฏูุน)",
            "- 'ุฎุทุฃ ูู ุฅุตุฏุงุฑ ุดูุงุฏุฉ ุฅุฑุณุงููุฉ' โ ุงูุฅุฑุณุงููุฉ (ูุดููุฉ ุชูููุฉ)",
            "- 'ุดุงุดุฉ ุณูุฏุงุก ุนูุฏ ุฅุตุฏุงุฑ ุดูุงุฏุฉ ุฅุฑุณุงููุฉ' โ ุงูุฅุฑุณุงููุฉ (ูุดููุฉ ุชูููุฉ)",
            "- 'ุนูุฏ ุชุณุฌูู ุงูููุดุงุฉ ูุงุถุงูุฉ ุจูุงูุงุชูุง ูุญุฏุซ ุฎุทุง' โ ุงูุชุณุฌูู", 
            "- 'ุจุนุฏ ุชุณุฌูู ุฏุฎูู ูุงุณุชููุงู ุงูุจูุงูุงุช ุธูุฑ ุงู ุงูุดุฑูุฉ ูุณุฌูุฉ' โ ุงูุชุณุฌูู",
            "- 'ูู ูุชู ุนูุณ ุงูุณุฏุงุฏ ูุทูุจ ูุฆุฉ ุงููุณูุญ' โ ุงููุฏููุนุงุช (ูุดููุฉ ุฏูุน)",
            "- 'ูุง ุฃุณุชุทูุน ุฏูุน ุฑุณูู ุงูุดูุงุฏุฉ' โ ุงููุฏููุนุงุช",
            "",
            "ุงููุฆุงุช ุงููุชุงุญุฉ ููุท (ุงุฎุชุฑ ูุงุญุฏุฉ ุจุงูุถุจุท ููุง ูู ููุชูุจุฉ):"
        ])
        
        # List all valid categories with similarity scores
        for i, category in enumerate(valid_categories, 1):
            relevance = ""
            for sim_cat in similar_categories:
                if sim_cat["name"] == category:
                    relevance = f" (ุชุดุงุจู: {sim_cat['similarity_score']:.2f})"
                    break
            prompt_parts.append(f"{i}. {category}{relevance}")
        
        prompt_parts.extend([
            "",
            "ุชุฐูุฑ: ุงุฎุชุฑ ููุท ูู ุงููุฆุงุช ุงููุฐููุฑุฉ ุฃุนูุงู ุจุงูุถุจุท ููุง ูู ููุชูุจุฉ.",
            "ุฃุฌุจ ุจุตูุบุฉ JSON ููุท:",
            '{"category": "ุงุณู ุงููุฆุฉ", "confidence": 0.95, "reasoning": "ุณุจุจ ุงูุงุฎุชูุงุฑ ูุน ุงูุชุทุจูู ุงููุจุงุดุฑ ููููุงุนุฏ"}'
        ])
        
        return "\n".join(prompt_parts)
    
    def _build_classification_prompt(self, text: str, similar_categories: List[Dict[str, Any]]) -> str:
        """Build classification prompt with context - DEPRECATED, use _build_strict_classification_prompt"""
        return self._build_strict_classification_prompt(text, similar_categories, 
                                                       list(self.hierarchy.categories.keys()) if self.hierarchy else [])
    
    def _extract_category_from_text(self, response: str, similar_categories: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Extract category from text response as fallback"""
        
        # Look for category names in the response
        response_lower = response.lower()
        
        for category in similar_categories:
            if category["name"].lower() in response_lower:
                return {
                    "category": category["name"],
                    "confidence": 0.7,  # Medium confidence for text extraction
                    "reasoning": f"Extracted from response: {response[:100]}...",
                    "classification_method": "text_extraction_fallback"
                }
        
        # If no match found, use first similar category
        if similar_categories:
            return {
                "category": similar_categories[0]["name"],
                "confidence": 0.5,
                "reasoning": "Fallback to most similar category",
                "classification_method": "similarity_fallback"
            }
        
        return {
            "category": "ุบูุฑ ูุญุฏุฏ",
            "confidence": 0.1,
            "reasoning": "No categories found in response",
            "classification_method": "unknown_fallback"
        }
    
    async def _validate_and_store_classification(self, state: TicketState, 
                                               classification_result: Dict[str, Any],
                                               similar_categories: List[Dict[str, Any]]):
        """Validate classification result and store in state - STRICT VERSION"""
        
        category = classification_result.get("category", "").strip()
        confidence = float(classification_result.get("confidence", 0.0))
        reasoning = classification_result.get("reasoning", "")
        
        # STRICT validation - must exist exactly in hierarchy
        valid_category = None
        if self.hierarchy and category in self.hierarchy.categories:
            valid_category = category
        else:
            self.logger.warning(f"Category '{category}' not found in hierarchy - using fallback")
            
            # Use the top similar category if it's valid
            if similar_categories:
                for sim_cat in similar_categories:
                    if sim_cat["name"] in self.hierarchy.categories:
                        valid_category = sim_cat["name"]
                        confidence = min(confidence * 0.7, sim_cat["similarity_score"])
                        reasoning += f" (strict fallback from '{category}' to valid category)"
                        break
            
            # Last resort - use a default valid category
            if not valid_category and self.hierarchy:
                valid_categories = list(self.hierarchy.categories.keys())
                if valid_categories:
                    valid_category = valid_categories[0]  # Use first valid category
                    confidence = 0.3
                    reasoning = f"Invalid category '{category}', using default"
        
        # Store for compatibility with pipeline metrics
        state.category_confidence = confidence
        
        # Add classification correction logging
        original_category = classification_result.get("category", "").strip()
        if original_category != valid_category:
            self.logger.warning(f"Category correction: '{original_category}' โ '{valid_category}' (strict validation)")
        
        # Ensure classification object has proper structure
        if not hasattr(state, 'classification') or state.classification is None:
            from ..models.ticket_state import TicketClassification
            state.classification = TicketClassification()
        
        # Store in classification object (primary storage location)
        state.classification.main_category = valid_category
        state.classification.confidence_score = confidence
        
        # Add category description if available
        if self.hierarchy and valid_category in self.hierarchy.categories:
            state.classification.main_category_description = self.hierarchy.categories[valid_category].description
        
        # Store classification metadata
        if not hasattr(state, 'classification_metadata'):
            state.classification_metadata = {}
        
        state.classification_metadata['category_agent'] = {
            'processing_timestamp': datetime.now().isoformat(),
            'original_llm_category': category,
            'final_category': valid_category,
            'similar_categories_found': len(similar_categories),
            'classification_method': classification_result.get("classification_method"),
            'confidence_threshold_met': confidence >= self.config.confidence_threshold,
            'reasoning': reasoning
        }
        
        # Set overall confidence flag
        state.classification_metadata['requires_review'] = confidence < self.config.confidence_threshold
        
        self.logger.info(f"Stored classification: {valid_category} (confidence: {confidence:.2f})")
    
    def _validate_output_state(self, state: TicketState) -> None:
        """Validate category classification results"""
        super()._validate_output_state(state)
        
        # Category classification specific validations
        if not hasattr(state, 'classification') or not state.classification.main_category:
            raise ValueError("Main category classification not completed")
        
        if not isinstance(getattr(state.classification, 'confidence_score', 0), (int, float)):
            raise ValueError("Main confidence score not set properly")
    
    async def get_classification_stats(self) -> Dict[str, Any]:
        """Get comprehensive classification statistics"""
        try:
            # Get Qdrant collection info
            collection_info = self.qdrant_client.get_collection(self.collection_name)
            
            stats = {
                'agent_metrics': self.metrics.dict(),
                'vector_collection': {
                    'vectors_count': collection_info.vectors_count,
                    'indexed_vectors_count': collection_info.indexed_vectors_count,
                    'points_count': collection_info.points_count
                },
                'classification_config': {
                    'embedding_model': self.embedding_model,
                    'top_k_candidates': self.top_k_candidates,
                    'similarity_threshold': self.similarity_threshold,
                    'confidence_threshold': self.config.confidence_threshold
                }
            }
            
            return stats
            
        except Exception as e:
            self.logger.error(f"Failed to get classification stats: {e}")
            return {'error': str(e)}
    
    async def add_category_examples(self):
        """Add common examples for each category to improve vector search"""
        category_examples = {
            "ุงูุชุณุฌูู": [
                "ุจุนุฏ ุชุณุฌูู ุฏุฎูู ูุงุณุชููุงู ุงูุจูุงูุงุช ุธูุฑ ูู ุงู ุงูุดุฑูู ูุณุฌูู",
                "ูุง ุฃุณุชุทูุน ุฅููุงู ุนูููุฉ ุงูุชุณุฌูู",
                "ุงูุชุญูู ูู ุงูุณุฌู ุงูุชุฌุงุฑู ูุง ูุนูู",
                "ุธูุฑุช ุฑุณุงูุฉ ุฃู ุงูุดุฑูุฉ ูุณุฌูุฉ ูุณุจูุงู"
            ],
            "ุชุณุฌูู ุงูุฏุฎูู": [
                "ูุง ุฃุณุชุทูุน ุชุณุฌูู ุงูุฏุฎูู ููููุตุฉ",
                "ูุณูุช ูููุฉ ุงููุฑูุฑ",
                "ุฑุณุงูุฉ ุฎุทุฃ ุนูุฏ ูุญุงููุฉ ุงูุฏุฎูู",
                "ุงูุญุณุงุจ ูููู ููุง ุฃุณุชุทูุน ุงูุฏุฎูู"
            ],
            "ุงูุฅุฑุณุงููุฉ": [
                "ุชู ุณุฏุงุฏ ูุงุชูุฑุฉ ุดูุงุฏุฉ ุงุฑุณุงููุฉ ููู ุชุธูุฑ ุงูุดูุงุฏุฉ",
                "ุญุงูุฉ ุงูุทูุจ ุจุงูุชุธุงุฑ ุงูุณุฏุงุฏ ูุน ุงูุนูู ุจุฃู ุงููุงุชูุฑุฉ ูุณุฏุฏู",
                "ูุง ุชุธูุฑ ุดูุงุฏุฉ ุงูุฅุฑุณุงููุฉ ุจุนุฏ ุงูุฏูุน",
                "ูุดููุฉ ูู ุฅุตุฏุงุฑ ุดูุงุฏุฉ ุงูุฅุฑุณุงููุฉ"
            ],
            "ุงููุฏููุนุงุช": [
                "ูุง ุฃุณุชุทูุน ุฏูุน ุงููุงุชูุฑุฉ",
                "ุฑุณุงูุฉ ุฎุทุฃ ุนูุฏ ูุญุงููุฉ ุงูุณุฏุงุฏ",
                "ุงููุจูุบ ุงููุทููุจ ุบูุฑ ุตุญูุญ",
                "ูุง ุชุธูุฑ ุทุฑู ุงูุฏูุน ุงููุชุงุญุฉ"
            ]
        }
        
        points = []
        # Get current max ID
        try:
            existing_points = self.qdrant_client.scroll(
                collection_name=self.collection_name,
                limit=1,
                with_payload=False
            )[0]
            point_id = len(existing_points) + 1
        except:
            point_id = 1000  # Start with a high ID to avoid conflicts
        
        for category, examples in category_examples.items():
            for example in examples:
                embedding = await self._get_embedding(example)
                if embedding:
                    point = PointStruct(
                        id=point_id,
                        vector=embedding,
                        payload={
                            "category_name": category,
                            "type": "training_example",
                            "example_text": example,
                            "added_for": "accuracy_improvement"
                        }
                    )
                    points.append(point)
                    point_id += 1
        
        if points:
            self.qdrant_client.upsert(
                collection_name=self.collection_name,
                points=points
            )
            self.logger.info(f"Added {len(points)} training examples to improve accuracy")

    async def update_category_examples(self, category: str, positive_examples: List[str], 
                                     negative_examples: List[str] = None):
        """Update few-shot examples for a specific category"""
        try:
            # Store examples in cache
            if category not in self.few_shot_cache:
                self.few_shot_cache[category] = {"positive": [], "negative": []}
            
            self.few_shot_cache[category]["positive"].extend(positive_examples)
            
            if negative_examples:
                self.few_shot_cache[category]["negative"].extend(negative_examples)
            
            # Add examples to vector collection for improved similarity search
            points = []
            point_id = len(self.qdrant_client.scroll(self.collection_name, limit=1)[0])
            
            for example in positive_examples:
                embedding = await self._get_embedding(example)
                if embedding:
                    point = PointStruct(
                        id=point_id,
                        vector=embedding,
                        payload={
                            "category_name": category,
                            "example_text": example,
                            "type": "positive_example",
                            "added_at": datetime.now().isoformat()
                        }
                    )
                    points.append(point)
                    point_id += 1
            
            if points:
                self.qdrant_client.upsert(
                    collection_name=self.collection_name,
                    points=points
                )
                self.logger.info(f"Added {len(points)} examples for category '{category}'")
            
        except Exception as e:
            self.logger.error(f"Failed to update category examples: {e}")

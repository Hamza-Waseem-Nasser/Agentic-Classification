"""
STEP 3: CATEGORY CLASSIFIER AGENT - MAIN CLASSIFICATION WITH VECTOR SEARCH

This agent performs the first level of classification, determining the main
category for each ticket using a combination of semantic search and LLM
classification. It leverages Qdrant vector database for efficient similarity matching.

KEY RESPONSIBILITIES:
1. Vector-Based Similarity Search: Use embeddings to find similar categories
2. LLM Classification: Use GPT-4 with few-shot examples for final decision
3. Confidence Scoring: Generate reliable confidence scores for classifications
4. Few-Shot Learning: Maintain and use relevant classification examples
5. Category Validation: Ensure classifications match the hierarchy

CLASSIFICATION PIPELINE:
Processed Text â†’ Embeddings â†’ Vector Search â†’ Top-K Categories â†’ LLM + Few-Shot â†’ Final Classification

DESIGN DECISIONS:
- Hybrid Approach: Combines vector similarity with LLM reasoning
- Qdrant Integration: Production-ready vector database for semantic search
- OpenAI Embeddings: High-quality text embeddings for Arabic text
- Few-Shot Learning: Dynamic example selection for improved accuracy
- Confidence Thresholds: Configurable confidence levels for quality control

VECTOR SEARCH STRATEGY:
- Embed category descriptions and examples in Qdrant
- Query with processed ticket text to find semantically similar categories
- Use top-5 candidates as context for LLM classification
- Combine embedding similarity with LLM reasoning for final decision

INTEGRATION POINTS:
- Qdrant Vector Database: Semantic search and similarity matching
- OpenAI Embeddings: Text-to-vector conversion for Arabic content
- CategoryLoader: Access to category hierarchy and metadata
- ArabicProcessingAgent: Uses processed and normalized text
"""

import asyncio
import json
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
import numpy as np

from qdrant_client import QdrantClient
from qdrant_client.http import models
from qdrant_client.http.models import Distance, VectorParams, PointStruct
from openai import AsyncOpenAI

from .base_agent import BaseAgent, BaseAgentConfig, AgentType
from ..models.ticket_state import TicketState
from ..models.entities import Category, ClassificationHierarchy


class CategoryClassifierAgent(BaseAgent):
    """
    Category Classifier Agent: Main category classification with vector search.
    
    Combines semantic similarity search using Qdrant with LLM-based classification
    to achieve high accuracy in determining the main category for each ticket.
    """
    
    def __init__(self, config: BaseAgentConfig, 
                 hierarchy: Optional[ClassificationHierarchy] = None,
                 qdrant_url: str = "http://localhost:6333",
                 collection_name: str = "itsm_categories"):
        super().__init__(config)
        
        self.hierarchy = hierarchy
        self.collection_name = collection_name
        self.qdrant_url = qdrant_url
        
        # Initialize Qdrant client
        self.qdrant_client = QdrantClient(url=qdrant_url)
        
        # Initialize OpenAI client for embeddings - with API key validation
        if not config.api_key:
            raise ValueError("OpenAI API key is required for embeddings")
        self.openai_client = AsyncOpenAI(api_key=config.api_key)
        
        # Classification parameters - get from config
        self.embedding_model = getattr(config, 'embedding_model', "text-embedding-3-small")
        self.top_k_candidates = getattr(config, 'top_k_candidates', 5)
        self.similarity_threshold = getattr(config, 'similarity_threshold', 0.5)
        
        # Few-shot examples cache
        self.few_shot_cache = {}
        
        # Add strict mode attributes (required for main.py integration)
        self.strict_mode = False
        self.classification_validator = None
        
        self.logger.info(f"Category Classifier initialized with Qdrant at {qdrant_url}")
        
        # Flag to track initialization status
        self._vector_collection_initialized = False
    
    @classmethod
    async def create(cls, config: BaseAgentConfig, 
                     hierarchy: Optional[ClassificationHierarchy] = None,
                     qdrant_url: str = "http://localhost:6333",
                     collection_name: str = "itsm_categories"):
        """
        Async factory method to properly initialize CategoryClassifierAgent.
        
        Args:
            config: Agent configuration
            hierarchy: Classification hierarchy
            qdrant_url: Qdrant server URL
            collection_name: Collection name for vectors
            
        Returns:
            Fully initialized CategoryClassifierAgent
        """
        instance = cls(config, hierarchy, qdrant_url, collection_name)
        await instance._initialize_vector_collection()
        return instance
    
    async def _initialize_vector_collection(self):
        """Initialize Qdrant collection for category vectors"""
        try:
            # Check if collection exists
            collections = self.qdrant_client.get_collections().collections
            collection_exists = any(col.name == self.collection_name for col in collections)
            
            if not collection_exists:
                # Create collection with appropriate vector size (1536 for text-embedding-3-small)
                self.qdrant_client.create_collection(
                    collection_name=self.collection_name,
                    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),
                )
                self.logger.info(f"Created Qdrant collection: {self.collection_name}")
                
                # Initialize with category data if hierarchy is available
                if self.hierarchy:
                    await self._populate_vector_collection()
            else:
                self.logger.info(f"Using existing Qdrant collection: {self.collection_name}")
            
            self._vector_collection_initialized = True
                
        except Exception as e:
            self.logger.error(f"Failed to initialize Qdrant collection: {e}")
            self._vector_collection_initialized = False
    
    async def _populate_vector_collection(self):
        """Populate Qdrant collection with category embeddings"""
        try:
            points = []
            point_id = 0
            
            for category_name, category in self.hierarchy.categories.items():
                # Create embeddings for category name and description
                category_text = f"{category.name} {category.description}"
                
                # Get embedding
                embedding = await self._get_embedding(category_text)
                
                if embedding:
                    # Create point for Qdrant
                    point = PointStruct(
                        id=point_id,
                        vector=embedding,
                        payload={
                            "category_name": category.name,
                            "category_description": category.description,
                            "subcategory_count": len(category.subcategories),
                            "keywords": list(category.keywords),
                            "type": "main_category"
                        }
                    )
                    points.append(point)
                    point_id += 1
                
                # Add subcategories as additional context
                for subcategory in category.subcategories.values():
                    subcategory_text = f"{subcategory.name} {subcategory.description}"
                    subcategory_embedding = await self._get_embedding(subcategory_text)
                    
                    if subcategory_embedding:
                        point = PointStruct(
                            id=point_id,
                            vector=subcategory_embedding,
                            payload={
                                "category_name": category.name,
                                "subcategory_name": subcategory.name,
                                "subcategory_description": subcategory.description,
                                "parent_category": category.name,
                                "type": "subcategory_context"
                            }
                        )
                        points.append(point)
                        point_id += 1
            
            # Upload points to Qdrant
            if points:
                self.qdrant_client.upsert(
                    collection_name=self.collection_name,
                    points=points
                )
                self.logger.info(f"Populated Qdrant with {len(points)} category embeddings")
            
        except Exception as e:
            self.logger.error(f"Failed to populate vector collection: {e}")
    
    async def _get_embedding(self, text: str) -> Optional[List[float]]:
        """Get OpenAI embedding for text"""
        try:
            response = await self.openai_client.embeddings.create(
                input=text,
                model=self.embedding_model
            )
            return response.data[0].embedding
        except Exception as e:
            self.logger.warning(f"Failed to get embedding for text: {e}")
            return None
    
    async def process(self, state: TicketState) -> TicketState:
        """
        Classify ticket into main category using vector search + LLM.
        
        Args:
            state: Ticket state with processed Arabic text
            
        Returns:
            Enhanced state with main category classification
        """
        self.logger.info(f"Starting category classification for ticket {state.ticket_id}")
        
        # Get processed text (should be available from Arabic agent)
        text = getattr(state, 'processed_text', None) or state.original_text
        
        if not text or not text.strip():
            raise ValueError("No text available for classification")
        
        # 1. Vector-based similarity search
        similar_categories = await self._find_similar_categories(text)
        
        # 2. LLM-based classification with context
        classification_result = await self._classify_with_llm(text, similar_categories)
        
        # 3. Validate and store results
        await self._validate_and_store_classification(state, classification_result, similar_categories)
        
        self.logger.info(f"Category classification complete: {classification_result.get('category', 'unknown')}")
        return state
    
    async def _find_similar_categories(self, text: str) -> List[Dict[str, Any]]:
        """Find similar categories using vector search"""
        try:
            # Check if Qdrant is properly initialized
            if not self.qdrant_client:
                self.logger.error("Qdrant client not initialized")
                return self._fallback_keyword_search(text)
            
            # Check if vector collection is initialized
            if not self._vector_collection_initialized:
                self.logger.warning("Vector collection not initialized, attempting to initialize...")
                await self._initialize_vector_collection()
                if not self._vector_collection_initialized:
                    return self._fallback_keyword_search(text)
            
            # Check collection exists
            try:
                collection_info = self.qdrant_client.get_collection(self.collection_name)
            except Exception:
                self.logger.warning("Collection not found, creating...")
                await self._initialize_vector_collection()
                if not self._vector_collection_initialized:
                    return self._fallback_keyword_search(text)
            
            # Get embedding for the input text
            query_embedding = await self._get_embedding(text)
            
            if not query_embedding:
                self.logger.warning("Failed to get embedding for query text")
                return self._fallback_keyword_search(text)
            
            # Search in Qdrant
            search_results = self.qdrant_client.search(
                collection_name=self.collection_name,
                query_vector=query_embedding,
                limit=self.top_k_candidates * 2,  # Get more results to filter
                score_threshold=self.similarity_threshold
            )
            
            # Process results and group by main category
            category_scores = {}
            
            for result in search_results:
                category_name = result.payload["category_name"]
                score = result.score
                
                if category_name in category_scores:
                    # Take the best score for each category
                    category_scores[category_name] = max(category_scores[category_name], score)
                else:
                    category_scores[category_name] = score
            
            # Sort by score and return top candidates
            sorted_categories = sorted(category_scores.items(), key=lambda x: x[1], reverse=True)
            
            similar_categories = []
            for category_name, score in sorted_categories[:self.top_k_candidates]:
                if self.hierarchy and category_name in self.hierarchy.categories:
                    category = self.hierarchy.categories[category_name]
                    similar_categories.append({
                        "name": category_name,
                        "description": category.description,
                        "similarity_score": score,
                        "subcategory_count": len(category.subcategories),
                        "keywords": list(category.keywords)
                    })
            
            self.logger.debug(f"Found {len(similar_categories)} similar categories")
            return similar_categories
            
        except Exception as e:
            self.logger.error(f"Vector search failed: {e}")
            return self._fallback_keyword_search(text)
    
    def _fallback_keyword_search(self, text: str) -> List[Dict[str, Any]]:
        """Fallback keyword-based search when vector search fails"""
        if not self.hierarchy:
            return []
        
        # Simple keyword matching as fallback
        text_lower = text.lower()
        matches = []
        
        for category_name, category in self.hierarchy.categories.items():
            score = 0
            
            # Check category name
            if category_name.lower() in text_lower:
                score += 0.8
            
            # Check keywords
            for keyword in category.keywords:
                if keyword.lower() in text_lower:
                    score += 0.3
            
            if score > 0:
                matches.append({
                    "name": category_name,
                    "description": category.description,
                    "similarity_score": min(score, 1.0),
                    "subcategory_count": len(category.subcategories),
                    "keywords": list(category.keywords),
                    "search_method": "keyword_fallback"
                })
        
        # Sort by score and return top candidates
        matches.sort(key=lambda x: x["similarity_score"], reverse=True)
        return matches[:self.top_k_candidates]
    
    async def _classify_with_llm(self, text: str, similar_categories: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Classify using LLM with similar categories as context"""
        
        if not self.llm:
            raise ValueError("LLM not available for classification")
        
        # Get exact category names from hierarchy
        valid_categories = list(self.hierarchy.categories.keys()) if self.hierarchy else []
        
        # Build classification prompt with EXACT categories
        prompt = self._build_strict_classification_prompt(text, similar_categories, valid_categories)
        
        try:
            from langchain_core.messages import HumanMessage, SystemMessage
            
            system_message = SystemMessage(content=f"""
            Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªØµÙ†ÙŠÙ ØªØ°Ø§ÙƒØ± Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ØªÙ‚Ù†ÙŠ Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª.
            
            Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹: ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ø§Ø®ØªÙŠØ§Ø± ÙØ¦Ø© Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© ÙÙ‚Ø·. Ù„Ø§ ØªØ®ØªØ±Ø¹ ÙØ¦Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©.
            
            Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© ÙÙ‚Ø· Ù‡ÙŠ:
            {', '.join(valid_categories)}
            
            Ø§Ø³ØªØ®Ø¯Ù… Chain-of-Thought reasoning:
            1. Ø£ÙˆÙ„Ø§Ù‹ØŒ Ø§Ù‚Ø±Ø£ Ø§Ù„Ù†Øµ ÙˆØ­Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
            2. Ø«Ø§Ù†ÙŠØ§Ù‹ØŒ Ù‚Ø§Ø±Ù† Ù…Ø¹ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©
            3. Ø«Ø§Ù„Ø«Ø§Ù‹ØŒ Ø§Ø®ØªØ± Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø£Ù†Ø³Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„
            
            Ø£Ø¬Ø¨ Ø¨ØµÙŠØºØ© JSON Ø¨Ø§Ù„Ø¶Ø¨Ø· ÙƒÙ…Ø§ ÙŠÙ„ÙŠ:
            {{"category": "Ø§Ø³Ù… Ø§Ù„ÙØ¦Ø© Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©", "confidence": 0.95, "reasoning": "Ø³Ø¨Ø¨ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± Ù…Ø¹ Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªÙÙƒÙŠØ±", "chain_of_thought": "Ø£ÙˆÙ„Ø§Ù‹: ... Ø«Ø§Ù†ÙŠØ§Ù‹: ... Ø«Ø§Ù„Ø«Ø§Ù‹: ..."}}
            """)
            
            human_message = HumanMessage(content=prompt)
            
            response = await self._safe_llm_call([system_message, human_message])
            
            # Parse JSON response
            try:
                result = json.loads(response.content)
                
                # STRICT validation - must be exact match
                if result.get("category") not in valid_categories:
                    # Find the most similar valid category from the similar_categories list
                    if similar_categories and similar_categories[0]["name"] in valid_categories:
                        result["category"] = similar_categories[0]["name"]
                        result["confidence"] = similar_categories[0]["similarity_score"]
                        result["reasoning"] = "Corrected to valid category from similarity search"
                    else:
                        # Default to first valid category if nothing matches
                        result["category"] = valid_categories[0] if valid_categories else "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
                        result["confidence"] = 0.3
                        result["reasoning"] = "No valid category match found"
                
                # Add metadata
                result["classification_method"] = "llm_with_vector_context_strict"
                result["similar_categories_used"] = len(similar_categories)
                
                return result
                
            except json.JSONDecodeError as e:
                self.logger.warning(f"Failed to parse LLM response as JSON: {e}")
                # Fallback to highest similarity category
                if similar_categories and similar_categories[0]["name"] in valid_categories:
                    return {
                        "category": similar_categories[0]["name"],
                        "confidence": similar_categories[0]["similarity_score"],
                        "reasoning": "Fallback to highest similarity match",
                        "classification_method": "vector_similarity_fallback"
                    }
                else:
                    return {
                        "category": valid_categories[0] if valid_categories else "ØºÙŠØ± Ù…Ø­Ø¯Ø¯",
                        "confidence": 0.1,
                        "reasoning": "Fallback to first valid category",
                        "classification_method": "fallback_unknown"
                    }
                
        except Exception as e:
            self.logger.error(f"LLM classification failed: {e}")
            
            # Fallback to highest similarity category
            if similar_categories and similar_categories[0]["name"] in valid_categories:
                return {
                    "category": similar_categories[0]["name"],
                    "confidence": similar_categories[0]["similarity_score"],
                    "reasoning": "Fallback to highest similarity match",
                    "classification_method": "vector_similarity_fallback"
                }
            else:
                return {
                    "category": valid_categories[0] if valid_categories else "ØºÙŠØ± Ù…Ø­Ø¯Ø¯",
                    "confidence": 0.1,
                    "reasoning": "No similar categories found",
                    "classification_method": "fallback_unknown"
                }
    
    def _build_strict_classification_prompt(self, text: str, similar_categories: List[Dict[str, Any]], 
                                           valid_categories: List[str]) -> str:
        """Build classification prompt with strict category enforcement and better context"""
        
        # Add decision tree guidance based on common patterns
        classification_guidance = {
            "Ø§Ù„ØªØ³Ø¬ÙŠÙ„": [
                "- Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ Ø¹Ù†: Ø¥Ù†Ø´Ø§Ø¡ Ø­Ø³Ø§Ø¨ Ø¬Ø¯ÙŠØ¯ØŒ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ¬Ø§Ø±ÙŠØŒ Ù…Ø´Ø§ÙƒÙ„ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„",
                "- ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©: ØªØ³Ø¬ÙŠÙ„ØŒ Ø³Ø¬Ù„ ØªØ¬Ø§Ø±ÙŠØŒ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¸Ù‡Ø± Ù„ÙŠØŒ Ø§Ù„Ø´Ø±ÙƒØ© Ù…Ø³Ø¬Ù„Ø©"
            ],
            "ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„": [
                "- Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ Ø¹Ù†: Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ù„Ù„Ù…Ù†ØµØ©ØŒ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±ØŒ Ù†Ø³ÙŠØª ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±",
                "- ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©: Ø¯Ø®ÙˆÙ„ØŒ Ù„ÙˆØ¬ÙŠÙ†ØŒ ÙƒÙ„Ù…Ø© Ù…Ø±ÙˆØ±ØŒ Ù„Ø§ Ø£Ø³ØªØ·ÙŠØ¹ Ø§Ù„Ø¯Ø®ÙˆÙ„"
            ],
            "Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†Ø´Ø£Ø©": [
                "- Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ Ø¹Ù†: ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø±ÙƒØ©ØŒ ØªØºÙŠÙŠØ± Ø¶Ø¨Ø§Ø· Ø§Ù„Ø§ØªØµØ§Ù„ØŒ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª",
                "- ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©: Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†Ø´Ø£Ø©ØŒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø´Ø±ÙƒØ©ØŒ Ø¶Ø§Ø¨Ø· Ø§ØªØµØ§Ù„"
            ],
            "Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ÙŠØ©": [
                "- Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ Ø¹Ù†: Ø´Ù‡Ø§Ø¯Ø§Øª Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ÙŠØ©ØŒ Ø­Ø§Ù„Ø© Ø·Ù„Ø¨ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ÙŠØ©ØŒ Ù…Ø´Ø§ÙƒÙ„ Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø´Ù‡Ø§Ø¯Ø©",
                "- ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©: Ø¥Ø±Ø³Ø§Ù„ÙŠØ©ØŒ Ø´Ù‡Ø§Ø¯Ø© Ø¥Ø±Ø³Ø§Ù„ÙŠØ©ØŒ Ø­Ø§Ù„Ø© Ø§Ù„Ø·Ù„Ø¨ØŒ Ù„Ù… ØªØ¸Ù‡Ø± Ø§Ù„Ø´Ù‡Ø§Ø¯Ø©"
            ],
            "Ø§Ù„Ù…Ø¯ÙÙˆØ¹Ø§Øª": [
                "- Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ Ø¹Ù†: Ø¯ÙØ¹ Ø§Ù„ÙÙˆØ§ØªÙŠØ±ØŒ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø³Ø¯Ø§Ø¯ØŒ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ù…Ø§Ù„ÙŠØ©",
                "- ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©: Ø¯ÙØ¹ØŒ Ø³Ø¯Ø§Ø¯ØŒ ÙØ§ØªÙˆØ±Ø©ØŒ Ø±Ø³ÙˆÙ…ØŒ Ù…Ø¨Ù„Øº"
            ]
        }
        
        prompt_parts = [
            "Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØµÙ†ÙŠÙ ØªØ°Ø§ÙƒØ± Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ Ù„Ù†Ø¸Ø§Ù… Ø³Ø§Ø¨Ø±. ØµÙ†Ù Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ø¥Ù„Ù‰ Ø¥Ø­Ø¯Ù‰ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© ÙÙ‚Ø·:",
            f"Ø§Ù„Ù†Øµ: {text}",
            "",
            "=== Ø¯Ù„ÙŠÙ„ Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø¯Ù‚ÙŠÙ‚ ==="
        ]
        
        # Add specific guidance for top categories
        for category in valid_categories[:5]:  # Focus on top 5 most relevant
            if category in classification_guidance:
                prompt_parts.append(f"\nğŸ“ {category}:")
                prompt_parts.extend(classification_guidance[category])
        
        prompt_parts.extend([
            "",
            "=== Ù‚Ø§Ø¹Ø¯Ø© Ù…Ù‡Ù…Ø© Ø¬Ø¯Ø§Ù‹ ===",
            "Ø¥Ø°Ø§ Ø°ÙƒØ± Ø§Ù„Ù†Øµ 'Ø³Ø¯Ø§Ø¯ ÙØ§ØªÙˆØ±Ø©' ÙˆÙ„ÙƒÙ† Ø§Ù„Ù…Ø´ÙƒÙ„Ø© ØªØªØ¹Ù„Ù‚ Ø¨Ø®Ø¯Ù…Ø© Ù…Ø¹ÙŠÙ†Ø© (Ù…Ø«Ù„ Ø´Ù‡Ø§Ø¯Ø© Ø¥Ø±Ø³Ø§Ù„ÙŠØ©)ØŒ",
            "ØµÙ†Ù Ø­Ø³Ø¨ Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù…ØªØ£Ø«Ø±Ø© ÙˆÙ„ÙŠØ³ Ø­Ø³Ø¨ Ø§Ù„Ø¯ÙØ¹. Ù…Ø«Ù„Ø§Ù‹:",
            "- 'ØªÙ… Ø³Ø¯Ø§Ø¯ ÙØ§ØªÙˆØ±Ø© Ø´Ù‡Ø§Ø¯Ø© Ø¥Ø±Ø³Ø§Ù„ÙŠØ© ÙˆÙ„Ù… ØªØ¸Ù‡Ø± Ø§Ù„Ø´Ù‡Ø§Ø¯Ø©' â† Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ÙŠØ©",
            "- 'Ù„Ø§ Ø£Ø³ØªØ·ÙŠØ¹ Ø¯ÙØ¹ Ø±Ø³ÙˆÙ… Ø§Ù„Ø´Ù‡Ø§Ø¯Ø©' â† Ø§Ù„Ù…Ø¯ÙÙˆØ¹Ø§Øª",
            "",
            "Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© ÙÙ‚Ø· (Ø§Ø®ØªØ± ÙˆØ§Ø­Ø¯Ø© Ø¨Ø§Ù„Ø¶Ø¨Ø· ÙƒÙ…Ø§ Ù‡ÙŠ Ù…ÙƒØªÙˆØ¨Ø©):"
        ])
        
        # List all valid categories with similarity scores
        for i, category in enumerate(valid_categories, 1):
            relevance = ""
            for sim_cat in similar_categories:
                if sim_cat["name"] == category:
                    relevance = f" (ØªØ´Ø§Ø¨Ù‡: {sim_cat['similarity_score']:.2f})"
                    break
            prompt_parts.append(f"{i}. {category}{relevance}")
        
        prompt_parts.extend([
            "",
            "ØªØ°ÙƒØ±: Ø§Ø®ØªØ± ÙÙ‚Ø· Ù…Ù† Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© Ø£Ø¹Ù„Ø§Ù‡ Ø¨Ø§Ù„Ø¶Ø¨Ø· ÙƒÙ…Ø§ Ù‡ÙŠ Ù…ÙƒØªÙˆØ¨Ø©.",
            "Ø£Ø¬Ø¨ Ø¨ØµÙŠØºØ© JSON ÙÙ‚Ø·:",
            '{"category": "Ø§Ø³Ù… Ø§Ù„ÙØ¦Ø©", "confidence": 0.95, "reasoning": "Ø³Ø¨Ø¨ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±"}'
        ])
        
        return "\n".join(prompt_parts)
    
    def _build_classification_prompt(self, text: str, similar_categories: List[Dict[str, Any]]) -> str:
        """Build classification prompt with context - DEPRECATED, use _build_strict_classification_prompt"""
        return self._build_strict_classification_prompt(text, similar_categories, 
                                                       list(self.hierarchy.categories.keys()) if self.hierarchy else [])
    
    def _extract_category_from_text(self, response: str, similar_categories: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Extract category from text response as fallback"""
        
        # Look for category names in the response
        response_lower = response.lower()
        
        for category in similar_categories:
            if category["name"].lower() in response_lower:
                return {
                    "category": category["name"],
                    "confidence": 0.7,  # Medium confidence for text extraction
                    "reasoning": f"Extracted from response: {response[:100]}...",
                    "classification_method": "text_extraction_fallback"
                }
        
        # If no match found, use first similar category
        if similar_categories:
            return {
                "category": similar_categories[0]["name"],
                "confidence": 0.5,
                "reasoning": "Fallback to most similar category",
                "classification_method": "similarity_fallback"
            }
        
        return {
            "category": "ØºÙŠØ± Ù…Ø­Ø¯Ø¯",
            "confidence": 0.1,
            "reasoning": "No categories found in response",
            "classification_method": "unknown_fallback"
        }
    
    async def _validate_and_store_classification(self, state: TicketState, 
                                               classification_result: Dict[str, Any],
                                               similar_categories: List[Dict[str, Any]]):
        """Validate classification result and store in state - STRICT VERSION"""
        
        category = classification_result.get("category", "").strip()
        confidence = float(classification_result.get("confidence", 0.0))
        reasoning = classification_result.get("reasoning", "")
        
        # STRICT validation - must exist exactly in hierarchy
        valid_category = None
        if self.hierarchy and category in self.hierarchy.categories:
            valid_category = category
        else:
            self.logger.warning(f"Category '{category}' not found in hierarchy - using fallback")
            
            # Use the top similar category if it's valid
            if similar_categories:
                for sim_cat in similar_categories:
                    if sim_cat["name"] in self.hierarchy.categories:
                        valid_category = sim_cat["name"]
                        confidence = min(confidence * 0.7, sim_cat["similarity_score"])
                        reasoning += f" (strict fallback from '{category}' to valid category)"
                        break
            
            # Last resort - use a default valid category
            if not valid_category and self.hierarchy:
                valid_categories = list(self.hierarchy.categories.keys())
                if valid_categories:
                    valid_category = valid_categories[0]  # Use first valid category
                    confidence = 0.3
                    reasoning = f"Invalid category '{category}', using default"
        
        # Store for compatibility with pipeline metrics
        state.category_confidence = confidence
        
        # Add classification correction logging
        original_category = classification_result.get("category", "").strip()
        if original_category != valid_category:
            self.logger.warning(f"Category correction: '{original_category}' â†’ '{valid_category}' (strict validation)")
        
        # Ensure classification object has proper structure
        if not hasattr(state, 'classification') or state.classification is None:
            from ..models.ticket_state import TicketClassification
            state.classification = TicketClassification()
        
        # Store in classification object (primary storage location)
        state.classification.main_category = valid_category
        state.classification.confidence_score = confidence
        
        # Add category description if available
        if self.hierarchy and valid_category in self.hierarchy.categories:
            state.classification.main_category_description = self.hierarchy.categories[valid_category].description
        
        # Store classification metadata
        if not hasattr(state, 'classification_metadata'):
            state.classification_metadata = {}
        
        state.classification_metadata['category_agent'] = {
            'processing_timestamp': datetime.now().isoformat(),
            'original_llm_category': category,
            'final_category': valid_category,
            'similar_categories_found': len(similar_categories),
            'classification_method': classification_result.get("classification_method"),
            'confidence_threshold_met': confidence >= self.config.confidence_threshold,
            'reasoning': reasoning
        }
        
        # Set overall confidence flag
        state.classification_metadata['requires_review'] = confidence < self.config.confidence_threshold
        
        self.logger.info(f"Stored classification: {valid_category} (confidence: {confidence:.2f})")
    
    def _validate_output_state(self, state: TicketState) -> None:
        """Validate category classification results"""
        super()._validate_output_state(state)
        
        # Category classification specific validations
        if not hasattr(state, 'classification') or not state.classification.main_category:
            raise ValueError("Main category classification not completed")
        
        if not isinstance(getattr(state.classification, 'confidence_score', 0), (int, float)):
            raise ValueError("Main confidence score not set properly")
    
    async def get_classification_stats(self) -> Dict[str, Any]:
        """Get comprehensive classification statistics"""
        try:
            # Get Qdrant collection info
            collection_info = self.qdrant_client.get_collection(self.collection_name)
            
            stats = {
                'agent_metrics': self.metrics.dict(),
                'vector_collection': {
                    'vectors_count': collection_info.vectors_count,
                    'indexed_vectors_count': collection_info.indexed_vectors_count,
                    'points_count': collection_info.points_count
                },
                'classification_config': {
                    'embedding_model': self.embedding_model,
                    'top_k_candidates': self.top_k_candidates,
                    'similarity_threshold': self.similarity_threshold,
                    'confidence_threshold': self.config.confidence_threshold
                }
            }
            
            return stats
            
        except Exception as e:
            self.logger.error(f"Failed to get classification stats: {e}")
            return {'error': str(e)}
    
    async def add_category_examples(self):
        """Add common examples for each category to improve vector search"""
        category_examples = {
            "Ø§Ù„ØªØ³Ø¬ÙŠÙ„": [
                "Ø¨Ø¹Ø¯ ØªØ³Ø¬ÙŠÙ„ Ø¯Ø®ÙˆÙ„ ÙˆØ§Ø³ØªÙƒÙ…Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¸Ù‡Ø± Ù„ÙŠ Ø§Ù† Ø§Ù„Ø´Ø±ÙƒÙ‡ Ù…Ø³Ø¬Ù„Ù‡",
                "Ù„Ø§ Ø£Ø³ØªØ·ÙŠØ¹ Ø¥ÙƒÙ…Ø§Ù„ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ³Ø¬ÙŠÙ„",
                "Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ Ù„Ø§ ÙŠØ¹Ù…Ù„",
                "Ø¸Ù‡Ø±Øª Ø±Ø³Ø§Ù„Ø© Ø£Ù† Ø§Ù„Ø´Ø±ÙƒØ© Ù…Ø³Ø¬Ù„Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹"
            ],
            "ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„": [
                "Ù„Ø§ Ø£Ø³ØªØ·ÙŠØ¹ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ù„Ù„Ù…Ù†ØµØ©",
                "Ù†Ø³ÙŠØª ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±",
                "Ø±Ø³Ø§Ù„Ø© Ø®Ø·Ø£ Ø¹Ù†Ø¯ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„",
                "Ø§Ù„Ø­Ø³Ø§Ø¨ Ù…Ù‚ÙÙ„ ÙˆÙ„Ø§ Ø£Ø³ØªØ·ÙŠØ¹ Ø§Ù„Ø¯Ø®ÙˆÙ„"
            ],
            "Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ÙŠØ©": [
                "ØªÙ… Ø³Ø¯Ø§Ø¯ ÙØ§ØªÙˆØ±Ø© Ø´Ù‡Ø§Ø¯Ø© Ø§Ø±Ø³Ø§Ù„ÙŠØ© ÙˆÙ„Ù… ØªØ¸Ù‡Ø± Ø§Ù„Ø´Ù‡Ø§Ø¯Ø©",
                "Ø­Ø§Ù„Ø© Ø§Ù„Ø·Ù„Ø¨ Ø¨Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ø³Ø¯Ø§Ø¯ Ù…Ø¹ Ø§Ù„Ø¹Ù„Ù… Ø¨Ø£Ù† Ø§Ù„ÙØ§ØªÙˆØ±Ø© Ù…Ø³Ø¯Ø¯Ù‡",
                "Ù„Ø§ ØªØ¸Ù‡Ø± Ø´Ù‡Ø§Ø¯Ø© Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ÙŠØ© Ø¨Ø¹Ø¯ Ø§Ù„Ø¯ÙØ¹",
                "Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø¥ØµØ¯Ø§Ø± Ø´Ù‡Ø§Ø¯Ø© Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ÙŠØ©"
            ],
            "Ø§Ù„Ù…Ø¯ÙÙˆØ¹Ø§Øª": [
                "Ù„Ø§ Ø£Ø³ØªØ·ÙŠØ¹ Ø¯ÙØ¹ Ø§Ù„ÙØ§ØªÙˆØ±Ø©",
                "Ø±Ø³Ø§Ù„Ø© Ø®Ø·Ø£ Ø¹Ù†Ø¯ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø³Ø¯Ø§Ø¯",
                "Ø§Ù„Ù…Ø¨Ù„Øº Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØºÙŠØ± ØµØ­ÙŠØ­",
                "Ù„Ø§ ØªØ¸Ù‡Ø± Ø·Ø±Ù‚ Ø§Ù„Ø¯ÙØ¹ Ø§Ù„Ù…ØªØ§Ø­Ø©"
            ]
        }
        
        points = []
        # Get current max ID
        try:
            existing_points = self.qdrant_client.scroll(
                collection_name=self.collection_name,
                limit=1,
                with_payload=False
            )[0]
            point_id = len(existing_points) + 1
        except:
            point_id = 1000  # Start with a high ID to avoid conflicts
        
        for category, examples in category_examples.items():
            for example in examples:
                embedding = await self._get_embedding(example)
                if embedding:
                    point = PointStruct(
                        id=point_id,
                        vector=embedding,
                        payload={
                            "category_name": category,
                            "type": "training_example",
                            "example_text": example,
                            "added_for": "accuracy_improvement"
                        }
                    )
                    points.append(point)
                    point_id += 1
        
        if points:
            self.qdrant_client.upsert(
                collection_name=self.collection_name,
                points=points
            )
            self.logger.info(f"Added {len(points)} training examples to improve accuracy")

    async def update_category_examples(self, category: str, positive_examples: List[str], 
                                     negative_examples: List[str] = None):
        """Update few-shot examples for a specific category"""
        try:
            # Store examples in cache
            if category not in self.few_shot_cache:
                self.few_shot_cache[category] = {"positive": [], "negative": []}
            
            self.few_shot_cache[category]["positive"].extend(positive_examples)
            
            if negative_examples:
                self.few_shot_cache[category]["negative"].extend(negative_examples)
            
            # Add examples to vector collection for improved similarity search
            points = []
            point_id = len(self.qdrant_client.scroll(self.collection_name, limit=1)[0])
            
            for example in positive_examples:
                embedding = await self._get_embedding(example)
                if embedding:
                    point = PointStruct(
                        id=point_id,
                        vector=embedding,
                        payload={
                            "category_name": category,
                            "example_text": example,
                            "type": "positive_example",
                            "added_at": datetime.now().isoformat()
                        }
                    )
                    points.append(point)
                    point_id += 1
            
            if points:
                self.qdrant_client.upsert(
                    collection_name=self.collection_name,
                    points=points
                )
                self.logger.info(f"Added {len(points)} examples for category '{category}'")
            
        except Exception as e:
            self.logger.error(f"Failed to update category examples: {e}")
